{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The5Outliers - <span style=\"background: linear-gradient(to right, #3458d6, #34d634); -webkit-background-clip: text; color: transparent;\">Wikispeedia Voyages</span>: why so many players pass through Geography or Countries to reach their target</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.stats import kurtosis\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from src.utils.HTMLParser import HTMLParser\n",
    "from src.data.data_loader import *\n",
    "from src.utils.helpers import *\n",
    "from src.models.networks import *\n",
    "\n",
    "parser = HTMLParser()\n",
    "parser.load_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data cleaning and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part loads, cleans the data, and defines useful datasets for further analysis. \n",
    "\n",
    "- `read_articles()` loads a list of valid article names, that is without special characters and discardig any invalid articles, like non-wikispedia articles or with missing categories\n",
    "- `parser.get_df_html_stats()` gathers wikispedia page statistics like number of links, link density, and structural information\n",
    "- `read_categories()` sorts for each category of a same article its different levels of sub categories \n",
    "- `read_links()` gathers all the links outward of a page \n",
    "- `read_shortest_path_matrix()` reads the matrix of shortest paths possible between two articles \n",
    "- `read_unfinished_paths()` and `read_finished_paths()` load the original unfinished and finished paths and clean them\n",
    "- `read_similartiy_matrix()` reads the matrix of semantic similarity between article names \n",
    "- `read_categories_matrix()` reads the matrix that describes the similarity between article's category levels and sub-levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_names = read_articles() \n",
    "df_html_stats = parser.get_df_html_stats()\n",
    "df_categories = read_categories()\n",
    "df_links = read_links()\n",
    "df_shortest_path = read_shortest_path_matrix()\n",
    "df_unfinished = read_unfinished_paths()\n",
    "df_finished = read_finished_paths() \n",
    "df_sm = read_similartiy_matrix() \n",
    "df_scat = read_categories_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Add features to articles and paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Article features \n",
    "In and out degree of articles are added. \n",
    "- **In degree** of an article corresponds to the number of links on other pages targetting an article \n",
    "- **Out degree** of an article corresponds to the number of links towards other pages on this article\n",
    "\n",
    "Some notes:\n",
    "- Some articles have no articles leading to it \n",
    "- Some articles lead to no other articles\n",
    "- Links do not consider duplicates inside the page (each link is considered to appear once, but this will be relaxed with HTML parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = pd.DataFrame(df_article_names).copy()\n",
    "\n",
    "# Compute in-degree (number of times each article is a target link)\n",
    "in_degree = df_links.groupby('linkTarget').size().reset_index(name=\"in_degree\")\n",
    "# Compute out-degree (link density: number of times each article is a source link)\n",
    "out_degree = df_links.groupby('linkSource').size().reset_index(name=\"out_degree\")\n",
    "\n",
    "# Merge in-degree and out-degree with df_article_names\n",
    "df_article = df_article.merge(in_degree, left_on='article', right_on='linkTarget', how='left')\n",
    "df_article = df_article.merge(out_degree, left_on='article', right_on='linkSource', how='left')\n",
    "df_article = df_article.drop(columns=['linkTarget', 'linkSource'])\n",
    "\n",
    "# Fill NaN values with 0, assuming no links imply zero counts for those articles\n",
    "df_article = df_article.fillna(0).astype({'in_degree': 'int', 'out_degree': 'int'})\n",
    "\n",
    "# add the html stats to the articles\n",
    "df_html_stats = df_html_stats.rename(columns={'article_name': 'article'})\n",
    "df_article = pd.merge(df_article, df_html_stats, how='inner')\n",
    "\n",
    "# add the category (level_1) to each articles\n",
    "category_map = dict(zip(df_categories[\"article\"], df_categories[\"level_1\"]))\n",
    "df_article[\"category\"] = df_article[\"article\"].map(category_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Path features \n",
    "New metrics are added to characterize the game paths. Specifically:\n",
    "\n",
    "- **Path Length** which accounts for the total number of articles in a path\n",
    "\n",
    "- **Back-Clicks** which indicates how many times the user revisited previous articles\n",
    "\n",
    "- **Cosine Similarity** which measures the semantic similarity between the source and target articles\n",
    "\n",
    "- **Shortest Path** which gives the length of the shortest path possible between the source and target articles\n",
    "\n",
    "- **Categories Similarity** which  measure the category similarity between the categories of the source and target articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add some useful metrics to each paths dataframe: shortest path, semantic similarity\n",
    "df_unfinished['cosine_similarity'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_unfinished['shortest_path'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_unfinished['path_length'] = df_unfinished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_unfinished['back_clicks'] = df_unfinished['path'].apply(lambda x: x.count('<'))\n",
    "df_unfinished['categories_similarity'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)\n",
    "\n",
    "df_finished['cosine_similarity'] = df_finished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_finished['shortest_path'] = df_finished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_finished['path_length'] = df_finished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_finished['back_clicks'] = df_finished['path'].apply(lambda x: x.count('<'))\n",
    "df_finished['categories_similarity'] = df_finished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Core results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Article features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.a. Distributions of words, links, and categories in articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    (\"total_words\", \"Number of Words in Article\"),\n",
    "    (\"abstract_words\", \"Number of Words in Article Abstract\"),\n",
    "    (\"link_density\", \"Links Density in Article\"),\n",
    "    (\"abstract_link_density\", \"Links Density in Article Abstract\"),\n",
    "    (\"num_sections\", \"Number of Sections in Article\"),\n",
    "    (\"num_subsections\", \"Number of Sub- Sections in Article\")\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 5))\n",
    "\n",
    "# Loop through metrics to create histograms\n",
    "for i, (metric, title) in enumerate(metrics):\n",
    "    row, col = divmod(i, 3)\n",
    "    sn.histplot(df_article, x=metric, bins=30, kde=True, ax=ax[row, col])\n",
    "    ax[row, col].set_title(title)\n",
    "    if col == 1 or col == 2:\n",
    "        ax[row, col].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Distribution of Article Metrics\", y=1.05, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : The data is right-skewed for most of metrics, indicating that while most articles adhere to certain standards of complexity and length, a small subset stands out as particularly detailed or interconnected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.b Articles Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which categories feature the most complex articles? To answer this question, letâ€™s identify the most complex articles and the categories they belong to. We define complexity based on factors such as the number of words, links, and sections within each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define palette for categories\n",
    "df_article[\"category\"]=df_article[\"article\"].apply(lambda x: df_categories[df_categories[\"article\"]==x][\"level_1\"].values[0] if len(df_categories[df_categories[\"article\"]==x][\"category\"].values)>0 else \"None\")\n",
    "categories = sorted(df_article[\"category\"].unique())\n",
    "palette_category = sn.color_palette(\"tab20\", len(categories))\n",
    "color_mapping = dict(zip(categories, palette_category))\n",
    "\n",
    "def add_legend_category(fig, palette_category=palette_category, categories=categories, bbox_to_anchor=(1.15, 0.85)):\n",
    "\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color=color, linestyle='', markersize=10) \n",
    "            for color in palette_category]\n",
    "    labels = categories\n",
    "    fig.legend(\n",
    "        handles, \n",
    "        labels, \n",
    "        bbox_to_anchor=bbox_to_anchor, \n",
    "        title=\"Categories\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15, 5))\n",
    "\n",
    "# Define the parameters for each subplot\n",
    "metrics = [\n",
    "    \"total_words\", \"link_density\", \"num_sections\",\n",
    "    \"abstract_words\", \"abstract_link_density\", \"num_subsections\"\n",
    "]\n",
    "\n",
    "# Loop through metrics and plot\n",
    "for i, metric in enumerate(metrics):\n",
    "    row, col = divmod(i, 3)\n",
    "    order = df_article.groupby(\"category\")[metric].mean().sort_values(ascending=False).reset_index()[\"category\"]\n",
    "    sn.barplot(\n",
    "        x=\"category\", \n",
    "        y=metric, \n",
    "        hue=\"category\", \n",
    "        palette=color_mapping, \n",
    "        data=df_article, \n",
    "        ax=ax[row, col], \n",
    "        order=order\n",
    "    )\n",
    "    ax[row, col].set_title(f'{metric.replace(\"_\", \" \").capitalize()} by Category')\n",
    "    ax[row, col].set_xticklabels([])\n",
    "    if row == 0 :\n",
    "        ax[row, col].set_xlabel('')\n",
    "\n",
    "add_legend_category(fig)\n",
    "\n",
    "plt.suptitle(\"Articles Complexity by Categories\", y=1, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : The category \"Countries\" stands out as a particularly complex topic, characterized by articles with the highest link density, the greatest number of category levels, and the longest abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.c Articles Popularity and Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a correlation between the number of links in an article and the frequency with which people interact with it in the game? Does this depend more on the in-degree or out-degree of the links? And is there a significant difference between the in-degree and out-degree of links? We will compare and investigate these factors to understand their impact on article interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "#Plot the most visited articles in finished paths\n",
    "all_articles = []\n",
    "df_finished['path'].apply(lambda x: all_articles.extend(x.split(';')))\n",
    "df_path_articles = pd.Series(all_articles).value_counts().rename_axis('article_name').reset_index(name='value_counts')\n",
    "df_path_articles[\"category\"]=df_path_articles[\"article_name\"].apply(lambda x: df_categories[df_categories[\"article\"]==x][\"level_1\"].values[0] if len(df_categories[df_categories[\"article\"]==x][\"category\"].values)>0 else \"None\")\n",
    "df_path_articles = df_path_articles[df_path_articles['article_name'] != '<']\n",
    "\n",
    "sn.barplot(x='value_counts', y='article_name', hue=\"category\", palette=color_mapping, data=df_path_articles.head(15), ax=ax[0])\n",
    "ax[0].set_title('Most visited articles in paths')\n",
    "ax[0].legend_.remove() \n",
    "\n",
    "for i, metric in enumerate([\"in_degree\", \"out_degree\"]):\n",
    "    sn.barplot(x=metric, y='article', hue=\"category\", palette=color_mapping, data=df_article.sort_values(metric, ascending=False).head(15), ax=ax[i+1])\n",
    "    ax[i+1].set_title(f'Articles with the most links ({metric.replace(\"_\", \" \").capitalize()}) (without duplicates)')\n",
    "    ax[i+1].legend_.remove()\n",
    "    ax[i+1].set_ylabel('')\n",
    "\n",
    "add_legend_category(fig)\n",
    "plt.suptitle(\"Correlation between article popularity and link density\", y=1, fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : We observe a significant overlap between the most visited articles and those with the highest degree. Additionally, the \"Countries\" category is prominently represented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Analyse user behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for patterns in user behaviour and try to understand how we could measure whether a game was difficult or not. Many different metrics can be considered, for instance:\n",
    "- Game duration\n",
    "- Game path length\n",
    "- Difficulty rating given for finished paths\n",
    "- Number of back-clicks needed\n",
    "- Whether a game was finished or not\n",
    "- For unfinished games, how the game was abandoned\n",
    "\n",
    "A combination of these parameters can help finding in which games users struggled. This will then allow to assess whether players struggle less in <span style=\"background: linear-gradient(to right, #3458d6, #34d634); -webkit-background-clip: text; color: transparent;\">Wikispeedia Voyages</span> than in other paths.\n",
    "\n",
    "Let's first have a look of how the difficulty measures are distributed amongst each other for finished paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.a Path duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find medians and kurtosis for both finished and unfinished\n",
    "median_finished = df_finished['durationInSec'].median()\n",
    "kurtosis_finished = kurtosis(df_finished['durationInSec'])\n",
    "median_unfinished = df_unfinished.groupby('type')['durationInSec'].median()\n",
    "kurtosis_unfinished = df_unfinished.groupby('type')['durationInSec'].apply(kurtosis)\n",
    "\n",
    "print(f\"The median duration of finished paths is {median_finished:.0f} seconds\")\n",
    "print(f\"The median duration of all unfinished paths is {df_unfinished['durationInSec'].median():.0f} seconds, among which :\")\n",
    "print(f\"  - The median duration of restart paths is {median_unfinished['restart']:.0f} seconds\")\n",
    "print(f\"  - The median duration of timeout paths is {median_unfinished['timeout']:.0f} seconds\")\n",
    "\n",
    "print(f\"Kurtosis of finished game durations: {kurtosis_finished:.2f}\")\n",
    "print(f\"Kurtosis of restart game durations: {kurtosis_unfinished['restart']:.2f}\")\n",
    "print(f\"Kurtosis of timeout game durations: {kurtosis_unfinished['timeout']:.2f}\")\n",
    "\n",
    "# Plotting histograms\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Unfinished games\n",
    "ax1 = plt.subplot(121)\n",
    "sn.histplot(df_unfinished, x='durationInSec', hue='type', bins=100)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Duration in seconds')\n",
    "plt.title('Histogram of game duration for unfinished games')\n",
    "\n",
    "# Finished games\n",
    "plt.subplot(122, sharey=ax1)\n",
    "sn.histplot(df_finished, x='durationInSec', bins=100, alpha=0.5, color='y')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Duration in seconds')\n",
    "plt.title('Histogram of game duration for finished games')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-out paths are games where the player stopped playing for more that 30 minutes. If we set those aside, and look at the duration of paths where the players decided to restart a new game, the mediam duration of games is 114 seconds, approximately the same as finished path duration of 107 seconds.\n",
    "\n",
    "The kurtosis in finished games is much higher than in unfinished restart games (3973 vs 45), meaning that finished games are more heavy tailed. We can in fact see very little players restart after 3000 seconds, whereas many finished games go beyond 6000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.b Path duration and path length vs. user rating\n",
    "\n",
    "Let's first look at path duration distribution over different user rating. We found similar results for finished and unfinished paths, so let's have a look at **finished ones** for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change metric to 'path_length' for path length \n",
    "metric = 'durationInSec' \n",
    "\n",
    "df_finished_strNaN = df_finished.copy()\n",
    "df_finished_strNaN['rating'] = df_finished_strNaN['rating'].fillna('NaN')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "blues_palette = sn.color_palette(\"Blues\", n_colors=6)\n",
    "\n",
    "means, stds = [], []\n",
    "ax1 = plt.subplot(231)\n",
    "sn.histplot(df_finished[df_finished_strNaN['rating']=='NaN'], x=metric, bins=50, log_scale=True, color=blues_palette[0]) \n",
    "mean = df_finished[df_finished_strNaN['rating']=='NaN'][metric].mean()\n",
    "plt.axvline(mean, color='red', label=f'Mean: {mean:.2f}', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Duration in seconds')\n",
    "plt.title('NaN')\n",
    "plt.legend()\n",
    "\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(231+i, sharex = ax1, sharey=ax1)\n",
    "    sn.histplot(df_finished[df_finished_strNaN['rating']==i], x=metric, bins=50, log_scale=True, color=blues_palette[i])\n",
    "    mean = df_finished[df_finished_strNaN['rating']==i][metric].mean()\n",
    "    plt.axvline(mean, color=\"red\", label=f'Mean: {mean:.2f}', linestyle='--')\n",
    "    plt.yscale('log')\n",
    "    plt.title(i)\n",
    "    plt.xlabel('Duration in seconds')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Path duration by rating of the finished paths', y=1.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of the path duration by rating are nice log-normal distributions! This means we can use the mean (location) and standard deviation (scale) to characterise them. Indeed, except for NaN, there is a steady increase of the path duration mean when rating goes up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at whether path duration is correlated with path length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_stats_duration = pd.DataFrame()\n",
    "df_path_stats_duration['mean'] = df_finished.groupby('rating', dropna=False)['durationInSec'].mean()\n",
    "df_path_stats_duration['std'] = df_finished.groupby('rating', dropna=False)['durationInSec'].std()\n",
    "df_path_stats_duration['sem'] = df_finished.groupby('rating', dropna=False)['durationInSec'].sem()\n",
    "\n",
    "df_path_stats_length = pd.DataFrame()\n",
    "df_path_stats_length['mean'] = df_finished.groupby('rating', dropna=False)['path_length'].mean()\n",
    "df_path_stats_length['std'] = df_finished.groupby('rating', dropna=False)['path_length'].std()\n",
    "df_path_stats_length['sem'] = df_finished.groupby('rating', dropna=False)['path_length'].sem()\n",
    "\n",
    "df_path_stats = pd.concat([df_path_stats_duration, df_path_stats_length], axis=1, keys=['duration', 'length'])\n",
    "\n",
    "df_path_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['NaN', '1.0', '2.0', '3.0', '4.0', '5.0']\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "sn.barplot(df_finished_strNaN, x='rating', y='durationInSec', order=order, errorbar=('ci', 95), color='#0b3880')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Duration in seconds')\n",
    "plt.subplot(122)\n",
    "sn.barplot(df_finished_strNaN, x='rating', y='path_length', order=order, errorbar=('ci', 95), color='#0b3880')\n",
    "plt.suptitle('Duration and Path Length by Rating of the Finished Paths')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Path Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear correlation between how long players took or how many clicks they made with the experienced difficulty rating. This means we can easily combine the two into a difficulty measure as they agree with each other on what players considered difficult. \n",
    "\n",
    "Let's now loow at back-clicks: could it indicate whether players had a hard time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.c Back-clicks\n",
    "The number of back-clicks made in a game may indicate players getting stuck.\n",
    "Lets investigate how this metric is related with player ratings, and if they are more prominent in certain categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will explain later (3.3) what filtering the most specific category really means\n",
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "paths_finished = extract_category_path(df_finished, df_categories_filtered)\n",
    "paths_finished = backtrack(paths_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "back_per_rating = paths_finished.groupby(\"rating\", dropna=False).agg({\"back_nb\": \"mean\", \"size\": \"mean\"}).reset_index()\n",
    "back_per_rating['Mean Back Clicks number'] = back_per_rating[\"back_nb\"]/back_per_rating[\"size\"]\n",
    "back_per_rating['rating'] = back_per_rating['rating'].fillna('NaN')\n",
    "sn.barplot(x=\"rating\", y='Mean Back Clicks number', hue=\"rating\", data=back_per_rating, palette=blues_palette[1:]+blues_palette[:1], ax=ax[0], legend=True)\n",
    "\n",
    "df_exploded = paths_finished.explode('category')\n",
    "category_back_mean = df_exploded.groupby(['category', 'rating'], dropna = False).size().reset_index(name='size')\n",
    "back_mean = df_exploded.groupby('category')[\"have_back\"].mean().reset_index().sort_values(by='have_back', ascending=False)\n",
    "category_back_mean = category_back_mean.merge(back_mean, on='category').sort_values(by='have_back', ascending=False)\n",
    "category_back_mean['rating_proportion'] = category_back_mean.groupby('category')['size'].transform(lambda x: x / x.sum())\n",
    "\n",
    "order = category_back_mean[\"category\"].unique()\n",
    "base_heights = category_back_mean[['category', 'have_back']].drop_duplicates().set_index('category')['have_back']\n",
    "df_pivot = category_back_mean.pivot(index='category', columns='rating', values='rating_proportion').fillna(0)\n",
    "df_pivot = df_pivot.reindex(order)\n",
    "\n",
    "\n",
    "bottom = pd.Series([0] * len(df_pivot), index=df_pivot.index)\n",
    "for i, rating in enumerate(df_pivot.columns):\n",
    "    ax[1].bar(df_pivot.index, \n",
    "           height=df_pivot[rating] * base_heights,  \n",
    "           bottom=bottom * base_heights,           \n",
    "           label=f'Rating {rating}', \n",
    "           color=blues_palette[i])\n",
    "    bottom += df_pivot[rating]\n",
    "\n",
    "ax[1].set_title('Mean Number of Path with Back-Clicks by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Mean Number of Path with Back-Clicks')\n",
    "plt.xticks(rotation=90)\n",
    "ax[0].set_title(\"Distribution of Back-Clicks per Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The back-clicks are correlated with the difficulty rating, which is expected as the more difficult a game is, the more likely players are to get stuck and go back.\n",
    "The category with the most back-clicks is \"Art\", and the one with the least is \"Countries\". This is interesting as \"Countries\" is also one of the most visited category, which might indicate that players are more familiar with it and therefore less likely to get stuck.\n",
    "Additionaly, The distribution of rating inside each category seams quite similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Look at articles as a categories types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.a Categories Distributions\n",
    "! Interactive plots with plotly need the notebook to be run but were replaced with screenshots for convenience. !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, parents, values, ids = create_treemap_data(df_categories)\n",
    "fig = go.Figure(go.Treemap(\n",
    "    labels=labels,\n",
    "    parents=parents,\n",
    "    values=values,\n",
    "    ids=ids,\n",
    "    textfont=dict(size=18),\n",
    "))\n",
    "fig.update_layout(margin=dict(t=50, l=10, r=10, b=5), title=\"Category Distribution in Articles Counting Every Category for Each Article\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./figures/33a.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We have {df_categories[\"level_1\"].unique().size} distinct level 1 categories.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each category is organized into multiple sub-levels, with a hierarchical depth of up to 3 levels.\n",
    "\n",
    "- For this analysis, we will focus exclusively on the most superficial level: Level 1.\n",
    "\n",
    "- Additionally, we observe that some articles are associated with multiple categories, highlighting overlaps and shared connections within the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Articles with Multiples Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First we count the numbers of articles with multiples categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of articles with multiples categories\n",
    "df_categories.groupby(\"article\")[\"article\"].size().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But if we constrain it only to different type of level 1 categories, it is reduced to :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique level 1 categories per article\n",
    "df_categories.groupby(\"article\")[\"level_1\"].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_abbreviations = {\n",
    "    'Art': 'Art',\n",
    "    'Mathematics': 'Math',\n",
    "    'IT': 'IT',\n",
    "    'Business Studies': 'BS',\n",
    "    'Music': 'Music',\n",
    "    'Religion': 'R',\n",
    "    'Language and literature': 'L&L',\n",
    "    'Citizenship': 'CIT',\n",
    "    'Countries': 'C',\n",
    "    'Design and Technology': 'D&T',\n",
    "    'Everyday life': 'Life',\n",
    "    'History': 'Hist',\n",
    "    'People': 'P',\n",
    "    'Geography': 'Geo',\n",
    "    'Science': 'Sci'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cooccurrence_cat_matrix(df_categories, category_abbreviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributing the **main category** to articles with multiple categories based on the category **with fewer total articles** helps prioritize specialization over generality. \n",
    "\n",
    "Categories with fewer total articles are typically more specific, while those with higher counts cover broader topics. By focusing on the category with fewer articles, we ensure the articleâ€™s primary focus is on a unique or specialized perspective, providing a clearer thematic assignment. This method promotes a balanced classification system, ensuring articles are categorized accurately without being overshadowed by more general categories.\n",
    "\n",
    "- For example, a category like **\"Geography\"** may encompass a wide range of topics, while **\"Countries\"** might be more specialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "\n",
    "labels_filtered, parents_filtered, values_filtered, ids_filtered = create_treemap_data(df_categories_filtered)\n",
    "fig = go.Figure(go.Treemap(\n",
    "    labels=labels_filtered,\n",
    "    parents=parents_filtered,\n",
    "    values=values_filtered,\n",
    "    ids=ids_filtered,\n",
    "    textfont=dict(size=18),\n",
    "))\n",
    "\n",
    "fig.update_layout(margin=dict(t=50, l=10, r=10, b=5), title=\"Category Distribution in Articles (Only the most specific category is shown for each article)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./figures/33a1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.b Transitions between categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to merge the finished and unfinished paths as in this section we will first only analyse how users make moves between categories of articles, independ of their succes on the research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_merged = pd.concat([df_finished, df_unfinished])\n",
    "common_paths = analyze_categories_paths(paths_merged, df_categories_filtered, omit_loops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_f = matrix_common_paths(common_paths)\n",
    "transition_cat_matrix(matrix_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is not the best way to visualise transitions between categories (this comes a bit later with graphs), it gives some important numerical values as first overview. Certain transitions seem to be more prominent than others, such as transitions from Geography to Countries or clicks to remain in Science. Generally, a lot of paths lead to Countries and Geography. Back-clicks, History and Science also have an overall strong presence. Does this give any real information about transitions users like or is it simply due to how many articles there are for the analysed categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_articles_pie_chart(df_categories_filtered, category_abbreviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geography is both a category that many articles have and a category with high transitions. This needs to be further analysed to see if users really choose to go through Geography or if they are just more likely to find an article with that category. The same cannot be said for Countries, which is a much smaller category which still has high transition counts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transitions within categories (including self-category)\n",
    "\n",
    "Example :\n",
    "- Science -> Science -> Science\n",
    "- Science -> Science -> Science -> Citizenship -> Design and Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data = get_position_frequencies(common_paths, max_position=15)\n",
    "plot_position_line(df_position_data, df_article, title=\"Position Frequencies for Finished Paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./figures/33a2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transitions within categories (excluding self-category)\n",
    "\n",
    "Let's remove the transitions in early articles that stay in the same category: if a player wants to leave a category but does not find an adequate link, we will only consider the next different category as next step.\n",
    "\n",
    "For example :\n",
    "- Science -> Science -> Science **becomes** Science\n",
    "- Science -> Science -> Science -> Citizenship -> Design and Technology **becomes** Science -> Citizenship -> Design and Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_paths_nl = analyze_categories_paths(paths_merged, df_categories_filtered, omit_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data = get_position_frequencies(common_paths_nl, max_position=15)\n",
    "plot_position_line(df_position_data, df_article, title=\"Position Frequencies for Finished Paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./figures/33a3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the categories in the early path positions are very often Countries or Geography. A lot of paths start in Science, but players seem to either leave in the first steps or stay there for the rest of the path. Very few start in Countries, but this category seems to be the most popular one to go to as a second step. For Geography, the trend is less clear but players still rather join the category than leave it in the second step.\n",
    "\n",
    "One last interesting analysis is that back-clicks seem to gain popularity as the paths get longer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transitions within categories of the optimal paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze whether usersâ€™ choice of categories at each position aligns with the categories in the optimal path to determine if passing through 'country' or 'geography' early in the path is an effective strategy for reaching the target. To achieve this, we first need to compute the optimal path by constructing a directed graph where edges represent connections between articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_paths = find_all_source_target_pairs(df_finished, df_unfinished, df_links)\n",
    "optimal_paths = calculate_optimal_path(df_links, optimal_paths, df_shortest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_paths = analyze_categories_paths(optimal_paths, df_categories_filtered, users=False, omit_loops=False)\n",
    "df_position_opt_data = get_position_frequencies(opt_paths, max_position=15)\n",
    "plot_position_line(df_position_opt_data, df_article, title=\"Position Frequencies for Optimal Paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./figures/33a4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, <span style=\"background: linear-gradient(to right, #3458d6, #34d634); -webkit-background-clip: text; color: transparent;\">Wikispeedia Voyages</span> seem to often be the ideal algorithmic path. This is interesting, but in the future we will need to also compare <i>human</i> best performance with the voyages to draw a conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with random path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_links = {article: data[\"total_links\"] for article, data in parser.parsed_articles.items()}\n",
    "random_path = pd.DataFrame(paths_merged[\"path\"].apply(lambda x: x.split(\";\")[0])).rename(columns={\"path\": \"start\"})\n",
    "random_path[\"path\"] = random_path[\"start\"].apply(generate_random_path, articles_links=articles_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_random_paths = analyze_categories_paths(random_path, df_categories_filtered, omit_loops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data_random = get_position_frequencies(common_random_paths, max_position=30)\n",
    "plot_position_line(df_position_data_random, df_article, title=\"Position Frequencies for Finished Paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_cat_proba, articles_categories_proba, articles_categories_list = compute_proba_links(df_categories, parser)\n",
    "# common_paths_nl[\"proba_path\"] = common_paths_nl[\"Category Path\"].apply(lambda x: compute_proba_path(x, cat_to_cat_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_paths_nl = analyze_categories_paths(paths_merged, df_categories_filtered, omit_loops=True)\n",
    "df_position_data = get_position_frequencies(common_paths_nl, max_position=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set(key for d in list(articles_categories_proba.values()) for key in d.keys())\n",
    "v = {k: [dic[k] if k in dic else np.NaN for dic in list(articles_categories_proba.values())] for k in keys}\n",
    "v = {k: np.mean(np.nan_to_num(value)) for k,value in v.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data['Adjusted Frequency'] = df_position_data['Category'].map(v)\n",
    "df_position_data[\"Frequency\"] = df_position_data[\"Frequency\"]/df_position_data['Adjusted Frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_position_line(df_position_data, df_article, title=\"Position Frequencies for Finished Paths normalized by link density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.c Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a network *(directed graph)* to represent user transitions between different categories of articles.\n",
    "\n",
    "- **Nodes:** Each node represents a group of articles belonging to a specific category, with each article assigned to his main category. \n",
    "- **Edges:** Each edge represents a transition from one article category to another, indicating the flow of user activity.\n",
    "\n",
    "In this visualization, we exclude transitions within the same category (self-loops), as these are already represented in the transition matrix shown earlier (3.3.b). The focus here is on how users navigate between different categories.\n",
    "\n",
    "The node positions are determined using a **force-directed algorithm**:\n",
    "\n",
    "- Nodes repel each other like charged particles, preventing overlaps.\n",
    "- Edges act like springs, pulling connected nodes closer to reflect their relationships.\n",
    "\n",
    "----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we recursively replace each back click **(<)** with the article that was visited prior to it. This ensures that we accurately reconstruct the original navigation path and correctly identify the corresponding category for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_merged_with_replace_back = paths_merged['path'].apply(replace_back_clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_network(paths_merged_with_replace_back, df_categories_filtered, include_self_loops=False)\n",
    "\n",
    "plot_network(G, title=\"Networks of transition whithin Categoires (exclude self loops)\", show_edge_labels=False, node_size=1000, node_abbreviations=category_abbreviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a clustered graph, with central clusters dominated by categories containing the largest number of articles, such as Science, Geography, People, and History. Additionally, we see Countries positioned close to the center,despite the small size of the category (only 5% of the total articles) reflecting its strong connections with these major categories.\n",
    "\n",
    "Next, we will normalize the edge weights by the total number of articles in the **source** category. This adjustment accounts for the imbalance in category sizes, ensuring a more accurate representation of transition dynamics.\n",
    "\n",
    "**Note:** Currently, we are normalizing by the size of the source node only. However, for future analyses, we plan to explore other normalization methods, such as accounting for the size of the target category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_normalized = normalize_edge_weights(G, df_categories_filtered)\n",
    "plot_network(G_normalized, title=\"Networks normalised by the category size of the source node (exclude self loops)\", show_edge_labels=False, node_size=1000, node_abbreviations=category_abbreviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalizing, we clearly observe that **Countries** becomes even more central in the graph, while the other categories spread out further, forming less distinct clusters.\n",
    "\n",
    "We also notice a particularly strong connection from Countries to Geography, which may be influenced by the fact that the current normalization only considers the size of the source category, not the target category.\n",
    "And the inherent logical relationship between Countries and Geography.\n",
    "\n",
    "- For future work, we aim to analyze the weights of each connection in greater detail to better understand these interdependencies and explore alternative normalization methods to capture the full dynamics of category relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_edge_weights(G_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Correlations and combination between previous results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.a Corelation between difficulty and combination of source-target categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a glance at the extend to which the choice of the source article and the end article affects the difficulty of the game.\n",
    "This could highlight potential combinations of categories that are harder to connect.\n",
    "\n",
    "Different difficulty metrics are used like path duration, path length in terms of number of clicks and user ratings. \n",
    "\n",
    "The number of back-clicks and its link with current difficulty mettrics and categories is also studied to explore whether it indicates difficulty as well.\n",
    "#### Correlation between the duration of game and the combination of source-target category\n",
    "Here the difficulty measure is the game duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished = find_categories_start_end(df_finished, df_categories_filtered)\n",
    "paths_unfinished = find_categories_start_end(df_unfinished, df_categories_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='durationInSec', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='durationInSec',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='Greens', ax=ax[0])\n",
    "ax[0].set_ylabel(\"Start Category\")\n",
    "ax[0].set_xlabel(\"End Category\")\n",
    "\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='Blues', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of Duration (seconds) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linking a music article to a language and litterature article is the combination that takes the longest time (â‰ˆ800s) to connect in finished paths. In unfinished paths, it takes â‰ˆ1300s, maybe indicating players tend to abandon due to difficulty? \n",
    "\n",
    "Curiously, connnecting art to mathematics is either very fast (<100s) in succesfull games, or takes a very long time (â‰ˆ2000s) in unsuccesfull ones, this is also observed in connecting mathematics to mathematics for example.\n",
    "\n",
    "In the other hand, connecting religion to religion takes a short time both in succesfull and unsuccesfull games. A short finished path might indicate easily connectable categories, whereas short unfinished paths could indicate early abandonment. Why would easilly conectable source and target lead to early abandonment for other players? Maybe this scenario can divide into two : either the target is directly on the source page or just a few clicks away, either they are not so close (for example linked to different religions), the density of links in the page might be low and the player might lack knowledge in the field. These potential causes will be analize in further parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between the length of path and the combination of source-target category\n",
    "Here the difficulty metric used is the number of clicks in the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished[\"steps_count\"] = paths_finished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "paths_unfinished[\"steps_count\"] = paths_unfinished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='steps_count', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='steps_count',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='Greens', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='Blues', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of length of path (number of steps) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between the player rating and the combination of source-target category\n",
    "Here we use the difficulty rating by the players as difficulty metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='rating', \n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='Greens', square=True)\n",
    "plt.title(\"Heatmap of rating for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some category combinations seem to be harder than others: Countries to Art of Mathematics to Religion seem to pose problems to players, while paths inside a category (the diagonal) seem to be generally perceived as easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methods for Further Analysis\n",
    "This section aims to show a few of the tools that will be useful along the way for our project. Instead of using them to answer our final question, we use them on the dataset as a whole to show that interesting information can be extracted from these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Similarity on paths\n",
    "\n",
    "Let's first get an intuition of how shortest paths are distributed and how articles are generally connected. The shortest path ranges from 1 to 9 if it exists, but it may also not exist at all (value -1). This means there are clusters of articles that are not linked to each other in the network. We can visualise this with a matrix that shows whether certain source and target articles are connected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shortest_paths_matrix(df_shortest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(df_shortest_path.values.flatten(), bins=np.arange(-1,11,1) - 0.5, alpha=0.7, edgecolor='black', color='black')\n",
    "plt.xlabel('Shortest Path Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Shortest Path Distances')\n",
    "plt.xticks(np.arange(-1,10,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.a Semantic Similarity\n",
    "\n",
    "An interesting way to figure out how players move through the wikispeedia network is semantic similarity. This encompasses both categories similarity and the abstract notion of \"meaning\". To concretise this notion, we consider two different measures of similarity:\n",
    "- semantic similarity based on article names embeddings\n",
    "- semantic similarity based on the Jaccard similarity of categories (with stronger weights for more specific categories)\n",
    "\n",
    "An interesting application is finding clusters of words that are more similar to each other than to words in other clusters. The clustering allows to reorder the similarity matrix in a way that regroups articles with high (or low) similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering\n",
    "sm = df_sm.to_numpy()\n",
    "linkage_matrix = linkage(sm, method='ward')\n",
    "ordered_indices = leaves_list(linkage_matrix)\n",
    "reordered_matrix = sm[ordered_indices, :][:, ordered_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(reordered_matrix, cmap='BuPu')\n",
    "plt.title('Reordered Similarity Matrix')\n",
    "plt.xlabel('Reordered Article Index')\n",
    "plt.ylabel('Reordered Article Index')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial threshold\n",
    "initial_threshold = 0.5\n",
    "\n",
    "# Function to plot the binary matrix based on a given threshold\n",
    "def plot_thresholded_matrix(threshold):\n",
    "    # Create a binary mask with the current threshold\n",
    "    binary_matrix = np.where(reordered_matrix >= threshold, 1, 0)\n",
    "    \n",
    "    # Plot the binary matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(binary_matrix, cmap='Reds', interpolation='nearest')\n",
    "    plt.title(f'Reordered Similarity Matrix (Threshold = {threshold:.2f})')\n",
    "    plt.xlabel('Reordered Article Index')\n",
    "    plt.ylabel('Reordered Article Index')\n",
    "    plt.colorbar(label='Above Threshold (1 = Red, 0 = White)')\n",
    "    plt.show()\n",
    "\n",
    "# Create the interactive slider\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=initial_threshold,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description='Threshold:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Display the slider and link it to the plotting function\n",
    "output = widgets.interactive_output(plot_thresholded_matrix, {'threshold': threshold_slider})\n",
    "display(threshold_slider, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./figures/41a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the reordered article indices make intuitive sense, similar words are regrouped. Words in the clusters with high similarity (similarity > 0.5) are words that appear more often in natural language, while words in the low-similarity areas are similar one to another, but not commonly used. This shows that we can regroup articles in clusters of 'well-known words' that are likely more present on user paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Words in high similarity clusters are for example {\", \".join(df_article_names[ordered_indices].iloc[1995:2005].tolist())}')\n",
    "print(f'Words in low similarity clusters are for example {\", \".join(df_article_names[ordered_indices].iloc[-7:].tolist())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.b Correlation between source-target similarity, and shortest possible path length\n",
    "Similar articles should be easier to connect, let's verify this using shortest possible path length as a difficulty measure.\n",
    "\n",
    "We will look at article's semantic symilarity using cosine similarity, and article's category similarity. Pearson and Spearman correlations will then be used to asses how significant these difficulty measures are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reds_palette = sn.dark_palette(\"salmon\", n_colors=len(df_finished['shortest_path'].unique()), reverse=True)\n",
    "blues_palette = sn.dark_palette(\"#69d\", n_colors=len(df_unfinished['shortest_path'].unique()), reverse=True)\n",
    "blues_palette = [blues_palette[-1]] + blues_palette[:-1] # put impossible paths in evidence\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Finished paths plot\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished, x='shortest_path', y='cosine_similarity', hue='shortest_path', legend=None, palette=reds_palette)\n",
    "plt.title('Finished paths')\n",
    "\n",
    "# Unfinished paths plot\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='cosine_similarity', hue='shortest_path', legend=None, palette=blues_palette)\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean cosine similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def calculate_correlations_with_shortestPath(df, column_name):\n",
    "    # Ensure 'shortest_path' is numeric\n",
    "    df['shortest_path'] = df['shortest_path'].astype(float)\n",
    "\n",
    "    pearson_corr, pearson_p = pearsonr(df['shortest_path'], df[column_name])\n",
    "    spearman_corr, spearman_p = spearmanr(df['shortest_path'], df[column_name])\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Pearson correlation: {pearson_corr:.4f}, p-value: {pearson_p:.4e}\")\n",
    "    print(f\"Spearman correlation: {spearman_corr:.4f}, p-value: {spearman_p:.4e}\")\n",
    "\n",
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished,\"cosine_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"cosine_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished, x='shortest_path', y='categories_similarity', hue='shortest_path', legend=None, palette=reds_palette)\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='categories_similarity', hue='shortest_path', legend=None, palette=blues_palette)\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean Categories Similarity per Shortest Path Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished,\"categories_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"categories_similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Pearson correlation** measures the linear relationship between two continuous variables. And the **Spearman correlation** assesses the monotonic relationship using ranked data, making it less sensitive to outliers and non-linear relationships.\n",
    "\n",
    "\n",
    "The article semantic similarity, and category similarity of finished paths have **moderate negative correlation** with path length (â‰ˆ-0.25), and the category similarity of unfinished paths has weak negative correlation (â‰ˆ-0.2).\n",
    "\n",
    "Both for articles and category similarity, the **p-values are zero**, showing high statistical significance. The observed correlations are thus unlikely to be due to random chance.\n",
    "\n",
    "Negative correlation indicates that as the minimal possible path length increases, the cosine similarity decreases.\n",
    "In other words, when the source and targets articles are close semantically, and their categories similar, the shortest possible path shrinkens, which makes sense as is it easier to connect 2 very similar articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Evolution of similarity on paths\n",
    "Now that we established similarity as a metric, can we see how mean similarity evolves on paths in general? Do we observe that users quickly try to leave a category in the first few clicks? Later this will be used to assess whether there is a difference for voyages and non-voyages, and whether there is a difference depending on the categories the path in made of, but for now this already gives an insight into what we can expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_finished_paths = [replace_back_clicks(path).split(';') for path in df_finished['path'].tolist()]\n",
    "path_similarities = []\n",
    "\n",
    "for path in all_finished_paths:\n",
    "    path_similarity = []\n",
    "    for step in range(len(path)-1):\n",
    "        current, next = path[step], path[step+1]\n",
    "        path_similarity.append(df_sm[current][next])\n",
    "\n",
    "    path_similarities.append(path_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example to understand what is going on. Each point represents a click of a user, to go from the first page (Batman) to the next (Chemistry). Batman and Chemistry are not strongly semantically related (hence the relatively low value of about 0.4). In the next step to Biology, the similarity is much higher (about 0.7), so the player first leave the category to reach the target category and then tends to stay there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_id = 1829\n",
    "path = path_similarities[path_id]\n",
    "plt.plot(range(len(path)), path, marker='o', color='#0c8714')\n",
    "plt.xticks([i-0.5 for i in range(len(path)+1)], all_finished_paths[path_id], rotation=90)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_N_path_similarity = {}\n",
    "for path_sim in path_similarities:\n",
    "    path_length = len(path_sim)\n",
    "    len_N_path_similarity.setdefault(path_length, []).append(path_sim)\n",
    "\n",
    "len_N_mean_similarity = {paths_len: np.mean(paths, axis=0) for paths_len, paths in len_N_path_similarity.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "greens_palette = sn.light_palette(\"#0c8714\", n_colors=10)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    sn.lineplot(len_N_mean_similarity[i+1], lw=1, label=i, color=greens_palette[i-1])\n",
    "plt.legend(title='# Link Clicks')\n",
    "plt.xlabel(\"Position of the Click in the Players' Paths\")\n",
    "plt.xticks(range(0, 11))\n",
    "plt.ylabel('Mean Semantic Similarity')\n",
    "plt.title('Mean Semantic Similarity Difference Aggregated by Path Lenghts')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear trend: in the first few clicks, the articles chosen have a low similarity to the previous one: this can be interpreted as leaving the original category. After this, the similarity for the next clicks stabilises, with only small fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Find Voyages\n",
    "\n",
    "A considerable number of users go through countries or articles about geography to find their target, irrespective of the categories of the initial and target articles: letâ€™s call this the <span style=\"background: linear-gradient(to right, #3458d6, #34d634); -webkit-background-clip: text; color: transparent;\">Wikispeedia Voyages</span>, and define it:\n",
    "\n",
    "Lets define a _Wikispeedia Voyage_ as a game in which the source is not in the categories Countries nor Geography, and that passes through articles in either those categories.\n",
    "\n",
    "### Sort games into voyage or not-voyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort paths into voyage and non-voyage\n",
    "df_finished_voyage = game_voyage_sorting(df_finished, df_categories_filtered, True, n=3)\n",
    "df_unfinished_voyage = game_voyage_sorting(df_unfinished, df_categories_filtered, False, n=3)\n",
    "\n",
    "# count the voyages \n",
    "voyage_count = (df_finished_voyage['voyage'] == 1).sum() + (df_unfinished_voyage['voyage'] == 1).sum()\n",
    "non_voyage_count = (df_finished_voyage['voyage'] == 0).sum() + (df_unfinished_voyage['voyage'] == 0).sum()\n",
    "\n",
    "print('Out of the ', len(df_finished_voyage)+len(df_unfinished_voyage), ' finished and unfinished games : ')\n",
    "print('  - ', voyage_count, ' are voyages')\n",
    "print('  - ', non_voyage_count, ' are not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all games in a dataframe and plot the sankey diagram \n",
    "df_all_voyage = pd.concat([df_finished_voyage, df_unfinished_voyage], ignore_index=True, sort=False)\n",
    "plot_sankey_voyage(df_all_voyage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./figures/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Analyse voyages\n",
    "### âžœ This is our milestone P3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare <span style=\"background: linear-gradient(to right, #3458d6, #34d634); -webkit-background-clip: text; color: transparent;\">Wikispeedia Voyages</span> with the other paths on the basis of experienced difficulty and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_names, df_html_stats, df_categories, df_links, df_shortest_path, df_unfinished, df_finished, df_sm, df_scat = read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished_voyage = game_voyage_sorting(df_finished, df_categories, True, n=3)\n",
    "df_unfinished_voyage = game_voyage_sorting(df_unfinished, df_categories, False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_voyage = pd.concat([df_finished_voyage, df_unfinished_voyage], ignore_index=True, sort=False)\n",
    "plot_sankey_voyage(df_all_voyage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs\n",
    "1. **INTRO**: On the top of the website, it is probably a good idea to be catchy and start with the Voyage vs Non-Voyage plot first (it gives a good but not too complex introduction). Then we can get over to justifications of the project choice and details\n",
    "2. **INTRODUCTORY STATS**: Be smart about figures, we really don't want too many here!\n",
    "   1. Have a statistic like the correlation between article popularity and link density (3.1.c) to highlight why Countries and Geography generally make sense to travel through as a motivation (slightly change the plot to make it more obvious and suitable for website). \n",
    "   2. As a second motivation, put the graph with Countries in the middle (and/or any other stats about categories in particular *if needed*, to show their prevalence in paths or in the dataset).\n",
    "   3. Then, a summary plot for the difficulty would probably be smart as it will be used in the main results.\n",
    "3. **CORE RESULTS**: for Voyage vs Non-Voyage, only keep the visuals for interesting results but mention the unsignificant ones. If we find nothing at first, we can look further into how to define Voyage vs Non-Voyage more precisely (e.g. only keeping Countries).\n",
    "   1. Article features (3.1.a) for the two classes\n",
    "   2. Difficulty measures (3.2), comparing path efficiencies in both classes. Do people in voyages succeed more for similar games? + comparing with shortest paths\n",
    "   3. Have some idea *when* people do voyages (and when they do not). Is it in difficult games? Any games? (difficulty based on start and end categories 3.4).\n",
    "   4. Similarity on paths, semantic detour\n",
    "   5. (Something causal about human reasoning if we find anything)\n",
    "4. Some conclusion + introducing further research ideas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
