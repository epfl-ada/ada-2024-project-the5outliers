{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import *\n",
    "from src.helpers import *\n",
    "from src.models.similarity_matrix import category_jaccard_similarity\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = htmlParser()\n",
    "parser.load_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: some interesting results or statistics about the raw data\n",
    "\n",
    "\"complete all the necessary descriptive statistics tasks\"\n",
    "\"show us that you have clear project goals\"\n",
    "\n",
    "- That you can handle the data in its size.\n",
    "- That you understand what’s in the data (formats, distributions, missing values, correlations, etc.).\n",
    "- That you considered ways to enrich, filter, transform the data according to your needs.\n",
    "- That you have a reasonable plan and ideas for methods you’re going to use, giving their essential mathematical details in the notebook.\n",
    "- That your plan for analysis and communication is reasonable and sound, potentially discussing alternatives to your choices that you considered but dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A- Data Cleaning\n",
    "\n",
    "- Steps done in data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_names = read_articles() \n",
    "df_html_stats = parser.get_df_html_stats()\n",
    "df_categories = read_categories()\n",
    "df_links = read_links()\n",
    "df_shortest_path = read_shortest_path_matrix()\n",
    "df_unfinished = read_unfinished_paths()\n",
    "df_finished = read_finished_paths() \n",
    "df_sm = read_similartiy_matrix()\n",
    "df_scat = category_jaccard_similarity(df_categories,{'level_1': 1, 'level_2': 2, 'level_3': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B- Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add some useful metrics to each paths dataframe: shortest path, semantic similarity\n",
    "df_unfinished['cosine_similarity'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_unfinished['shortest_path'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_unfinished['path_length'] = df_unfinished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_unfinished['back_clicks'] = df_unfinished['path'].apply(lambda x: x.count('<'))\n",
    "df_unfinished[\"categories_similarity\"] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)\n",
    "\n",
    "df_finished['cosine_similarity'] = df_finished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_finished['shortest_path'] = df_finished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_finished['path_length'] = df_finished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_finished['back_clicks'] = df_finished['path'].apply(lambda x: x.count('<'))\n",
    "df_finished[\"categories_similarity\"] = df_finished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: -1 with no errorbar makes no sense. 1 with no error bar makes sense (trivial case where start=target and similarity with itself=1)\n",
    "\n",
    "df_finished_clean = df_finished[df_finished['shortest_path'] != 0].copy()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished_clean, x='shortest_path', y='cosine_similarity')\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='cosine_similarity')\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean cosine similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def calculate_correlations_with_shortestPath(df, column_name):\n",
    "    # Ensure 'shortest_path' is numeric\n",
    "    df['shortest_path'] = df['shortest_path'].astype(float)\n",
    "\n",
    "    pearson_corr, pearson_p = pearsonr(df['shortest_path'], df[column_name])\n",
    "    spearman_corr, spearman_p = spearmanr(df['shortest_path'], df[column_name])\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Pearson correlation: {pearson_corr:.4f}, p-value: {pearson_p:.4e}\")\n",
    "    print(f\"Spearman correlation: {spearman_corr:.4f}, p-value: {spearman_p:.4e}\")\n",
    "\n",
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished_clean,\"cosine_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"cosine_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: -1 with no errorbar makes no sense. 1 with no error bar makes sense (trivial case where start=target and similarity with itself=1)\n",
    "# impossible paths in unfinishes paths are possible however. check if it is sound though because of the previous problem.\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished_clean, x='shortest_path', y='categories_similarity')\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='categories_similarity')\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean categories_similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished_clean,\"categories_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"categories_similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pearson Correlation\n",
    "Measures the linear relationship between two continuous variables.\n",
    "\n",
    "- Spearman Correlation\n",
    "Assesses the monotonic relationship using ranked data, making it less sensitive to outliers and non-linear relationships.\n",
    "\n",
    "The p-values are effectively zero, which is highly significant statistically. This suggests that the observed correlations are unlikely to be due to random chance.\n",
    "\n",
    "-> Thus as the distance path increase, the cosine_similarity decrease\n",
    "In other words..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulty measure\n",
    "Find patterns in user behaviour and try to understand how we could measure whether a game was difficult or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE OUTLIERS THAT MAKE NO SENSE\n",
    "\n",
    "#df_game_durations = pd.concat([df_finished[['durationInSec', 'type']], df_unfinished[['durationInSec', 'type']]], ignore_index=True)\n",
    "print(f\"The mean duration of finished paths is {df_finished['durationInSec'].mean():.0f} seconds\")\n",
    "print(f\"The mean duration of unfinished paths is {df_unfinished['durationInSec'].mean():.0f} seconds\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax1 = plt.subplot(121)\n",
    "sn.histplot(df_unfinished, x='durationInSec', hue='type', bins=75)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of game duration for unfinished games')\n",
    "\n",
    "plt.subplot(122, sharey = ax1)\n",
    "sn.histplot(df_finished, x='durationInSec', bins=75, alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of game duration for finished games')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted = df_unfinished[df_unfinished['type']=='timeout']['durationInSec'].sort_values()\n",
    "sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted = df_finished['durationInSec'].sort_values(ascending=False)\n",
    "sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_path_stats_duration = pd.DataFrame()\n",
    "df_path_stats_duration['mean'] = df_finished.groupby('rating', dropna=False)['durationInSec'].mean()\n",
    "df_path_stats_duration['std'] = df_finished.groupby('rating', dropna=False)['durationInSec'].std()\n",
    "df_path_stats_duration['sem'] = df_finished.groupby('rating', dropna=False)['durationInSec'].sem()\n",
    "\n",
    "\n",
    "df_path_stats_length = pd.DataFrame()\n",
    "df_path_stats_length['mean'] = df_finished.groupby('rating', dropna=False)['path_length'].mean()\n",
    "df_path_stats_length['std'] = df_finished.groupby('rating', dropna=False)['path_length'].std()\n",
    "df_path_stats_length['sem'] = df_finished.groupby('rating', dropna=False)['path_length'].sem()\n",
    "\n",
    "\n",
    "df_path_stats = pd.concat([df_path_stats_duration, df_path_stats_length], axis=1, keys=['duration', 'length'])\n",
    "\n",
    "df_path_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those are some nice log-normal distributions -> are they though? the distribution is normal in loglog, not log.\n",
    "# except for NaN, there is a steady increase of the path duration mean when rating goes up\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "means, stds = [], []\n",
    "ax1 = plt.subplot(231)\n",
    "sn.histplot(df_finished[df_finished['rating'].isnull()], x='durationInSec', bins=50) # change x to x = 'path_length' for path length\n",
    "means.append(df_finished[df_finished['rating'].isnull()]['durationInSec'].mean())\n",
    "stds.append(df_finished[df_finished['rating'].isnull()]['durationInSec'].std())\n",
    "plt.axvline(means[0], color='red')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('NaN')\n",
    "\n",
    "\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(231+i, sharex = ax1, sharey=ax1)\n",
    "    means.append(df_finished[df_finished['rating']==i]['durationInSec'].mean())\n",
    "    stds.append(df_finished[df_finished['rating']==i]['durationInSec'].std())\n",
    "    sn.histplot(df_finished[df_finished['rating']==i], x='durationInSec', bins=50)\n",
    "    plt.axvline(means[i], color='red')\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.title(i)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Path duration by rating', y=1.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "sn.histplot(df_finished, x='path_length', bins=50)\n",
    "plt.yscale('log')\n",
    "plt.xlim(0, 120)\n",
    "\n",
    "plt.subplot(122)\n",
    "sn.histplot(df_finished, x='back_clicks', bins=50)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories distribution in start and end paths between finished and unfinished games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished = find_categories_start_end(df_finished, df_categories)\n",
    "paths_unfinished = find_categories_start_end(df_unfinished, df_categories)\n",
    "\n",
    "paths_finished[\"finished\"] = 1\n",
    "paths_unfinished[\"finished\"] = 0\n",
    "\n",
    "paths = pd.concat([paths_finished, paths_unfinished], join='inner')\n",
    "paths_melted = paths.melt(\n",
    "    id_vars=[\"finished\"],\n",
    "    value_vars=[\"start_category\", \"end_category\"],\n",
    "    var_name=\"category_type\",\n",
    "    value_name=\"category\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color palette based on unique categories\n",
    "unique_categories = paths_melted['category'].unique()\n",
    "palette = sn.color_palette(\"Set1\", n_colors=len(unique_categories))\n",
    "color_mapping = dict(zip(unique_categories, palette))\n",
    "\n",
    "g = sn.FacetGrid(\n",
    "    data=paths_melted,\n",
    "    col=\"finished\",\n",
    "    row=\"category_type\",\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    "    margin_titles=True,\n",
    "    height=4,\n",
    ")\n",
    "\n",
    "g.map_dataframe(\n",
    "    sn.countplot,\n",
    "    x=\"category\",\n",
    "    hue=\"category\",\n",
    "    palette=color_mapping,\n",
    "    order=paths_melted['category'].value_counts().index  # Order by frequency\n",
    ")\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "for ax in g.axes.flatten():\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of duration of path between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='durationInSec', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='durationInSec',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='BuPu', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of Duration (seconds) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of length of path between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished[\"steps_count\"] = paths_finished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "paths_unfinished[\"steps_count\"] = paths_unfinished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='steps_count', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='steps_count',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='BuPu', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of length of path (number of steps) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of rating between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='rating', \n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu')\n",
    "plt.title(\"Heatmap of rating for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the rating, the backclip number and the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "paths_finished = extract_category_path(df_finished, df_categories_filtered)\n",
    "paths_finished = backtrack(paths_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "back_per_rating = paths_finished.groupby(\"rating\").agg({\"back_nb\": \"mean\", \"size\": \"mean\"}).reset_index()\n",
    "back_per_rating['Mean Back Clicks number'] = back_per_rating[\"back_nb\"]/back_per_rating[\"size\"]\n",
    "sn.barplot(x=\"rating\", y='Mean Back Clicks number', hue=\"rating\", data=back_per_rating, palette=sn.color_palette('viridis'), ax=ax[0])\n",
    "\n",
    "df_exploded = paths_finished.explode('category')\n",
    "category_back_mean = df_exploded.groupby(['category', 'rating']).size().reset_index(name='size')\n",
    "back_mean = df_exploded.groupby('category')[\"have_back\"].mean().reset_index().sort_values(by='have_back', ascending=False)\n",
    "category_back_mean = category_back_mean.merge(back_mean, on='category').sort_values(by='have_back', ascending=False)\n",
    "category_back_mean['rating_proportion'] = category_back_mean.groupby('category')['size'].transform(lambda x: x / x.sum())\n",
    "\n",
    "order = category_back_mean[\"category\"].unique()\n",
    "base_heights = category_back_mean[['category', 'have_back']].drop_duplicates().set_index('category')['have_back']\n",
    "df_pivot = category_back_mean.pivot(index='category', columns='rating', values='rating_proportion').fillna(0)\n",
    "df_pivot = df_pivot.reindex(order)\n",
    "\n",
    "colors = sn.color_palette('viridis')\n",
    "\n",
    "bottom = pd.Series([0] * len(df_pivot), index=df_pivot.index)\n",
    "for i, rating in enumerate(df_pivot.columns):\n",
    "    ax[1].bar(df_pivot.index, \n",
    "           height=df_pivot[rating] * base_heights,  \n",
    "           bottom=bottom * base_heights,           \n",
    "           label=f'Rating {rating}', \n",
    "           color=colors[i])\n",
    "    bottom += df_pivot[rating]\n",
    "\n",
    "ax[1].set_title('Mean Number of Path with Back Clicks by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Mean Number of Path with Back Clicks')\n",
    "plt.xticks(rotation=90)\n",
    "ax[0].set_title(\"Distribution of Back Clicks per Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that irrespective of the start and end categories, many players path through countries and geography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort games into voyage or not-voyage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort david's categories-paths into voyage or not voyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#david preprocessing  \n",
    "df_finished = df_finished.loc[~df_finished['path'].str.contains('Pikachu'), :]\n",
    "df_unfinished = df_unfinished.loc[~df_unfinished['target'].str.contains('Pikachu'), :]\n",
    "df_unfinished = df_unfinished.loc[~df_unfinished['path'].str.contains('Pikachu'), :]\n",
    "# one category per article \n",
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "#Science->Science->Science  become  Science\n",
    "common_paths_f_nl = analyze_categories_paths(df_finished, df_categories_filtered, omit_loops=True)\n",
    "common_paths_u_nl = analyze_categories_paths(df_unfinished, df_categories_filtered, omit_loops=True)\n",
    "\n",
    "# sort paths into voyage and not voyage\n",
    "common_paths_f_nl = category_voyage_sorting(common_paths_f_nl,1,2)\n",
    "common_paths_u_nl = category_voyage_sorting(common_paths_u_nl,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_paths_f_nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort games into voyage or not voyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished_voyage = game_voyage_sorting(df_finished, df_categories, True, n=3)\n",
    "df_unfinished_voyage = game_voyage_sorting(df_unfinished, df_categories, False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished_voyage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity\n",
    "An interesting way to figure out how players move through the wikispeedia network is semantic similarity. This encompasses both categories similarity and the abstract notion of \"meaning\". To concretise this notion, we consider two different measures of similarity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(df_sm, cmap='BuPu')\n",
    "cbar = fig.colorbar(cax)\n",
    "plt.title('Cosine similarity of article names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_triangle_indices = np.triu_indices_from(similarity_matrix, k=1) # Flatten the upper triangle of the matrix without the diagonal for sorting\n",
    "\n",
    "# Get the sorted indices for most similar pairs (descending order)\n",
    "sorted_similar_indices = np.argsort(-similarity_matrix[upper_triangle_indices])\n",
    "top_similar_pairs = list(zip(upper_triangle_indices[0][sorted_similar_indices], \n",
    "                             upper_triangle_indices[1][sorted_similar_indices]))\n",
    "\n",
    "print(\"Top 5 most similar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_similar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {similarity_matrix[idx1, idx2]:.4f}\")\n",
    "\n",
    "sorted_dissimilar_indices = np.argsort(similarity_matrix[upper_triangle_indices])\n",
    "top_dissimilar_pairs = list(zip(upper_triangle_indices[0][sorted_dissimilar_indices], \n",
    "                                upper_triangle_indices[1][sorted_dissimilar_indices]))\n",
    "\n",
    "# Print the top 5 most dissimilar pairs\n",
    "print(\"\\nTop 5 most dissimilar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_dissimilar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {similarity_matrix[idx1, idx2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Analysis (Hierarchical Clustering)\n",
    "Find clusters of words that are more similar to each other than to words in other clusters. At the bottom of the tree, most similar pairs are formed, then pairs of pairs are compared and so on. Check out <a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html> this link </a> for more detail and <a href=https://stackoverflow.com/questions/66969893/scipy-and-the-hierarchical-clustering-input> this </a> or <a href=https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial> this link </a> to get a somewhat intuitive idea how how 2D clustering works. The clustering allows to reorder the similarity matrix in a way that regroups articles with high similarity. More analysis needs to be done to understand what the clusters essentially are and represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, leaves_list\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "linkage_matrix = linkage(similarity_matrix, method='ward')\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(linkage_matrix)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Article Index (sorted by similarity)')\n",
    "plt.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    bottom=False,      \n",
    "    top=False,    \n",
    "    labelbottom=False)\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_indices = leaves_list(linkage_matrix)\n",
    "reordered_matrix = similarity_matrix[ordered_indices, :][:, ordered_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(reordered_matrix, cmap='BuPu')\n",
    "plt.title('Reordered Similarity Matrix')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The reordered article indices make intuitive sense, similar words are regrouped')\n",
    "print(df_article_names[ordered_indices].head(10))\n",
    "print(df_article_names[ordered_indices].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of similarity on paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unfinished = read_unfinished_paths()\n",
    "df_finished = read_finished_paths()\n",
    "\n",
    "all_paths = []\n",
    "df_finished['path'].apply(lambda x: all_paths.append(x.split(';')))\n",
    "for path in all_paths:\n",
    "    for step in range(len(path)):\n",
    "        if path[step] == '<':\n",
    "            path[step] = path[step-2]\n",
    "\n",
    "step_similarity = []\n",
    "\n",
    "for path in all_paths:\n",
    "    path_similarity = []\n",
    "    for step in range(len(path)-1):\n",
    "        current, next = sm.get_indices(df_article_names, [path[step], path[step+1]])\n",
    "        path_similarity.append(similarity_matrix[current, next])\n",
    "\n",
    "    step_similarity.append(path_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_similarity = []\n",
    "for N in range(1, 17):\n",
    "    paths_len_N = []\n",
    "    for path in step_similarity:\n",
    "        if len(path)==N:\n",
    "            paths_len_N.append(path)\n",
    "\n",
    "    paths_similarity.append(np.array(paths_len_N))\n",
    "means = [np.mean(paths_len_N, axis=0) for paths_len_N in paths_similarity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "for i in range(len(paths_similarity)):\n",
    "    plt.subplot(4, 4, 1+i)\n",
    "    plt.plot(paths_similarity[i].T, 'b.', alpha=0.5)\n",
    "    plt.plot(means[i], 'r', lw=2)\n",
    "    plt.title(f'Path length {i}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### html Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = htmlParser()\n",
    "print(f'There are {len(parser.article_URLs)} valid articles')\n",
    "\n",
    "df_html_articles = parser.article_names # The html articles in the data\n",
    "df_article_names = read_articles() # The articles used in the paths-and-graph data\n",
    "intersect = pd.merge(df_html_articles, df_article_names, how='inner', on=\"article\")\n",
    "print(f'There are {len(df_article_names)} articles in the paths-and-graph data and {len(intersect)} of those are in the html articles.')\n",
    "difference = df_html_articles[~df_html_articles.isin(df_article_names)]\n",
    "print(f'This means there are {len(difference)} articles more in the html data, such as \"{difference.iloc[0]}\", \"{difference.iloc[5]}\" or \"{difference.iloc[10]}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parser.parse_html_article(parser.article_URLs[266])\n",
    "if parsed: parser.get_overview(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_stats = parser2.get_df_html_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "sort_column = widgets.Dropdown(\n",
    "    options=df_html_stats.columns,\n",
    "    value='total_words',\n",
    "    description='Sort by:'\n",
    ")\n",
    "\n",
    "n_slider = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Number (n):'\n",
    ")\n",
    "\n",
    "# Display function to update table based on widget values\n",
    "def display_sorted(n, sort_by):\n",
    "    sorted_df = df_html_stats.sort_values(by=sort_by, ascending=False)\n",
    "    top_n = sorted_df.head(n)\n",
    "    bottom_n = sorted_df.tail(n)\n",
    "    \n",
    "    print(f\"\\nTop {n} Articles by {sort_by}:\")\n",
    "    display(top_n)\n",
    "    print(f\"\\nBottom {n} Articles by {sort_by}:\")\n",
    "    display(bottom_n)\n",
    "\n",
    "# Link widgets to display function\n",
    "widgets.interactive(display_sorted, n=n_slider, sort_by=sort_column)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
