{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style= \"color: #c7c9cf\">The5Outliers - </span><span style=\"background: linear-gradient(to right, #3458d6, #34d634); -webkit-background-clip: text; color: transparent;\">Wikispeedia Voyages</span><span style= \"color: #c7c9cf\">: why so many players pass through Geography or Countries to reach their target</span></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data_loader import *\n",
    "from src.helpers import *\n",
    "from src.htmlParser import htmlParser\n",
    "\n",
    "parser = htmlParser()\n",
    "parser.load_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: blablal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A- Data Cleaning\n",
    "This part loads, cleans the data, and defines useful datasets for further analysis. \n",
    "\n",
    "- `read_articles()` loads a list of valid article names, that is without special characters and discardig any invalid articles, like non-wikispedia articles or with missing categories\n",
    "- `parser.get_df_html_stats()` gathers wikispedia page statistics like number of links, link density, and structural information\n",
    "- `read_categories()` sorts for each category of a same article its different levels of sub categories \n",
    "- `read_links()` gathers all the links outward of a page \n",
    "- `read_shortest_path_matrix()` reads the matrix of shortest paths possible between two articles \n",
    "- `read_unfinished_paths()` and `read_finished_paths()` load the original unfinished and finished paths and clean them\n",
    "- `read_similartiy_matrix()` reads the matrix of semantic similarity between article names \n",
    "- `read_categories_matrix()` reads the matrix that describes the similarity between article's category levels and sub-levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_names = read_articles() \n",
    "df_html_stats = parser.get_df_html_stats()\n",
    "df_categories = read_categories()\n",
    "df_links = read_links()\n",
    "df_shortest_path = read_shortest_path_matrix()\n",
    "df_unfinished = read_unfinished_paths()\n",
    "df_finished = read_finished_paths() \n",
    "df_sm = read_similartiy_matrix() \n",
    "df_scat = read_categories_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more atributes to the articles itself with parsing and more!!!\n",
    "# TODO: Logic we have differents approaches (the paths connections withins articles, the articles it self, the categories...)\n",
    "\n",
    "df_article = pd.DataFrame(df_article_names).copy()\n",
    "\n",
    "# Compute in-degree (number of times each article is a target link)\n",
    "in_degree = df_links.groupby('linkTarget').size().reset_index(name=\"in_degree\")\n",
    "# Compute out-degree (link density: number of times each article is a source link)\n",
    "out_degree = df_links.groupby('linkSource').size().reset_index(name=\"out_degree\")\n",
    "\n",
    "# Merge in-degree and out-degree with df_article_names\n",
    "df_article = df_article.merge(in_degree, left_on='article', right_on='linkTarget', how='left')\n",
    "df_article = df_article.merge(out_degree, left_on='article', right_on='linkSource', how='left')\n",
    "df_article = df_article.drop(columns=['linkTarget', 'linkSource'])\n",
    "\n",
    "# Fill NaN values with 0, assuming no links imply zero counts for those articles\n",
    "df_article = df_article.fillna(0).astype({'in_degree': 'int', 'out_degree': 'int'})\n",
    "\n",
    "df_article\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numbers of articles != Numbers of articles with a least one **link** directing to it\n",
    "- May be more links per Article, if the same link repeat again througth the artcile, need to confirm by looking at the text or HTML\n",
    "- Numbers of articles != Numbers of articles with a least one **link** to another article in the corpus\n",
    "\n",
    "To explore more basic stufs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B- Exploratory Data Analysis\n",
    "\n",
    "Let's explore article features and player behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New metrics are added to characterize the game paths. Specifically:\n",
    "\n",
    "- **Path Length** which accounts for the total number of articles in a path\n",
    "\n",
    "- **Back Clicks** which indicates how many times the user revisited previous articles\n",
    "\n",
    "- **Cosine Similarity** which measures the semantic similarity between the source and target articles\n",
    "\n",
    "- **Shortest Path** which gives the length of the shortest path possible between the source and target articles\n",
    "\n",
    "- **Categories Similarity** which  measure the category similarity between the categories of the source and target articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add some useful metrics to each paths dataframe: shortest path, semantic similarity\n",
    "df_unfinished['cosine_similarity'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_unfinished['shortest_path'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_unfinished['path_length'] = df_unfinished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_unfinished['back_clicks'] = df_unfinished['path'].apply(lambda x: x.count('<'))\n",
    "df_unfinished[\"categories_similarity\"] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)\n",
    "\n",
    "df_finished['cosine_similarity'] = df_finished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_finished['shortest_path'] = df_finished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_finished['path_length'] = df_finished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_finished['back_clicks'] = df_finished['path'].apply(lambda x: x.count('<'))\n",
    "df_finished[\"categories_similarity\"] = df_finished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulty measures\n",
    "Let's look for patterns in user behaviour and article characteristics and try to understand how we could measure whether a game was difficult or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between source-target similarity, and shortest possible path length\n",
    "Similar articles should be easier to connect, let's verify this using shortest possible path length as a difficulty measure.\n",
    "\n",
    "We will look at article's semantic symilarity using cossine similarity, and article's category similarity. Pearson and Spearman correlations will then be used to asses how significant these difficulty measures are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: -1 with no errorbar makes no sense. 1 with no error bar makes sense (trivial case where start=target and similarity with itself=1)\n",
    "\n",
    "df_finished_clean = df_finished[df_finished['shortest_path'] != 0].copy()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished_clean, x='shortest_path', y='cosine_similarity')\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='cosine_similarity')\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean cosine similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def calculate_correlations_with_shortestPath(df, column_name):\n",
    "    # Ensure 'shortest_path' is numeric\n",
    "    df['shortest_path'] = df['shortest_path'].astype(float)\n",
    "\n",
    "    pearson_corr, pearson_p = pearsonr(df['shortest_path'], df[column_name])\n",
    "    spearman_corr, spearman_p = spearmanr(df['shortest_path'], df[column_name])\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Pearson correlation: {pearson_corr:.4f}, p-value: {pearson_p:.4e}\")\n",
    "    print(f\"Spearman correlation: {spearman_corr:.4f}, p-value: {spearman_p:.4e}\")\n",
    "\n",
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished_clean,\"cosine_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"cosine_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: -1 with no errorbar makes no sense. 1 with no error bar makes sense (trivial case where start=target and similarity with itself=1)\n",
    "# impossible paths in unfinishes paths are possible however. check if it is sound though because of the previous problem.\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished_clean, x='shortest_path', y='categories_similarity')\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='categories_similarity')\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean categories_similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished_clean,\"categories_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"categories_similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Pearson correlation** measures the linear relationship between two continuous variables. And the **Spearman correlation** assesses the monotonic relationship using ranked data, making it less sensitive to outliers and non-linear relationships.\n",
    "\n",
    "\n",
    "The article semantic similarity, and category similarity of finished paths have **moderate negative correlation** with path length (≈-0.25), and the category similarity of unfinished paths has weak negative correlation (≈-0.2).\n",
    "\n",
    "Both for articles and category similarity, the **p-values are zero**, showing high statistical significance. The observed correlations are thus unlikely to be due to random chance.\n",
    "\n",
    "Negative correlation indicates that as the minimal possible path length increases, the cosine_similarity decreases.\n",
    "In other words, when the source and targets articles are close semantically, and their categories similar, the shortest possible path shrinkens, which makes sense as is it easier to connect 2 very similar articles. The correlations are however moderate to weak, indicating that even if this true in general, closely related source and target are not sufficient to explain this form of difficulty. We therefore aim to find other difficulty measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game duration distribution, and correlation with difficulty rating \n",
    "Let's first see how time spent on a game is distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean duration of finished paths is {df_finished['durationInSec'].mean():.0f} seconds\")\n",
    "print(f\"The mean duration of unfinished paths is {df_unfinished['durationInSec'].mean():.0f} seconds\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax1 = plt.subplot(121)\n",
    "sn.histplot(df_unfinished, x='durationInSec', hue='type', bins=75)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of game duration for unfinished games')\n",
    "\n",
    "plt.subplot(122, sharey = ax1)\n",
    "sn.histplot(df_finished, x='durationInSec', bins=75, alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of game duration for finished games')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_stats_duration = pd.DataFrame()\n",
    "df_path_stats_duration['mean'] = df_finished.groupby('rating', dropna=False)['durationInSec'].mean()\n",
    "df_path_stats_duration['std'] = df_finished.groupby('rating', dropna=False)['durationInSec'].std()\n",
    "df_path_stats_duration['sem'] = df_finished.groupby('rating', dropna=False)['durationInSec'].sem()\n",
    "\n",
    "df_path_stats_length = pd.DataFrame()\n",
    "df_path_stats_length['mean'] = df_finished.groupby('rating', dropna=False)['path_length'].mean()\n",
    "df_path_stats_length['std'] = df_finished.groupby('rating', dropna=False)['path_length'].std()\n",
    "df_path_stats_length['sem'] = df_finished.groupby('rating', dropna=False)['path_length'].sem()\n",
    "\n",
    "df_path_stats = pd.concat([df_path_stats_duration, df_path_stats_length], axis=1, keys=['duration', 'length'])\n",
    "\n",
    "df_path_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those are some nice log-normal distributions -> are they though? the distribution is normal in loglog, not log. MAYBE POWER LAW IDK\n",
    "# except for NaN, there is a steady increase of the path duration mean when rating goes up\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "means, stds = [], []\n",
    "ax1 = plt.subplot(231)\n",
    "sn.histplot(df_finished[df_finished['rating'].isnull()], x='durationInSec', bins=50) # change x to x = 'path_length' for path length\n",
    "plt.axvline(df_finished[df_finished['rating'].isnull()]['durationInSec'].mean(), color='red')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('NaN')\n",
    "\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(231+i, sharex = ax1, sharey=ax1)\n",
    "    sn.histplot(df_finished[df_finished['rating']==i], x='durationInSec', bins=50)\n",
    "    plt.axvline(df_finished[df_finished['rating']==i]['durationInSec'].mean(), color='red')\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.title(i)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Path duration by rating', y=1.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path lenght and number of back clicks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "sn.histplot(df_finished, x='path_length', bins=50)\n",
    "plt.yscale('log')\n",
    "plt.xlim(0, 120)\n",
    "\n",
    "plt.subplot(122)\n",
    "sn.histplot(df_finished, x='back_clicks', bins=50)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories distribution in start and end articles \n",
    "The aim here is to look whether categories of the source and target articles are correlated with finishing or not a game. \n",
    "\n",
    "🚨 ici ce serait pas mieux de mettre les counts en pourcentage? ou alors est ce que le aim est different de ce que j'ai mit ??🚨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished = find_categories_start_end(df_finished, df_categories)\n",
    "paths_unfinished = find_categories_start_end(df_unfinished, df_categories)\n",
    "\n",
    "paths_finished[\"finished\"] = 1\n",
    "paths_unfinished[\"finished\"] = 0\n",
    "\n",
    "paths = pd.concat([paths_finished, paths_unfinished], join='inner')\n",
    "paths_melted = paths.melt(\n",
    "    id_vars=[\"finished\"],\n",
    "    value_vars=[\"start_category\", \"end_category\"],\n",
    "    var_name=\"category_type\",\n",
    "    value_name=\"category\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color palette based on unique categories\n",
    "unique_categories = paths_melted['category'].unique()\n",
    "palette = sn.color_palette(\"Set1\", n_colors=len(unique_categories))\n",
    "color_mapping = dict(zip(unique_categories, palette))\n",
    "\n",
    "g = sn.FacetGrid(\n",
    "    data=paths_melted,\n",
    "    col=\"finished\",\n",
    "    row=\"category_type\",\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    "    margin_titles=True,\n",
    "    height=4,\n",
    ")\n",
    "\n",
    "g.map_dataframe(\n",
    "    sn.countplot,\n",
    "    x=\"category\",\n",
    "    hue=\"category\",\n",
    "    palette=color_mapping,\n",
    "    order=paths_melted['category'].value_counts().index  # Order by frequency\n",
    ")\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "for ax in g.axes.flatten():\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corelation between difficulty and combination of source-target categories\n",
    "Let's get a glance at the extend to which the choice of the source article and the end article affects the difficulty of the game.\n",
    "This could highlight potential combinations of categories that are harder to connect.\n",
    "\n",
    "Different difficulty metrics are used like path duration, path length in terms of number of clicks and user ratings. \n",
    "\n",
    "The number of backclicks and its link with current difficulty mettrics and categories is also studied to explore whether it indicates difficulty as well.\n",
    "#### Correlation between the duration of game and the combination of source-target category\n",
    "Here the difficulty measure is the game duration. \n",
    "\n",
    "🚨put different colors for finished ans unfinished, so the colorbar isnt the same for diffrent scales🚨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='durationInSec', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='durationInSec',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='BuPu', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of Duration (seconds) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linking a music article to a language and litterature article is the combination that takes the longest time (≈800s) to connect in finished paths. In unfinished paths, it takes ≈1300s, maybe indicating players tend to abandon due to difficulty? \n",
    "\n",
    "Curiously, connnecting art to mathematics is either very fast (<100s) in succesfull games, or takes a very long time (≈2000s) in unsuccesfull ones, this is also observed in connecting mathematics to mathematics for example.\n",
    "\n",
    "In the other hand, connecting religion to religion takes a short time both in succesfull and unsuccesfull games. A short finished path might indicate easily connectable categories, whereas short unfinished paths could indicate early abandonment. Why would easilly conectable source and target lead to early abandonment for other players? Maybe this scenario can divide into two : either the target is directly on the source page or just a few clicks away, either they are not so close (for example linked to different religions), the density of links in the page might be low and the player might lack knowledge in the field. These potential causes will be analize in further parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between the length of path and the combination of source-target category\n",
    "Here the difficulty metric used is the number of clicks in the game. \n",
    "\n",
    "🚨put different colors for finished ans unfinished, so the colorbar isnt the same for diffrent scales🚨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished[\"steps_count\"] = paths_finished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "paths_unfinished[\"steps_count\"] = paths_unfinished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='steps_count', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='steps_count',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='BuPu', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of length of path (number of steps) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between the player rating and the combination of source-target category\n",
    "Here we use the difficulty rating by the players as difficulty metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='rating', \n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu')\n",
    "plt.title(\"Heatmap of rating for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the rating, the backclip number and the topics\n",
    "Here we explore to which extend the backclicks might be correlated with difficulty and topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "paths_finished = extract_category_path(df_finished, df_categories_filtered)\n",
    "paths_finished = backtrack(paths_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "back_per_rating = paths_finished.groupby(\"rating\").agg({\"back_nb\": \"mean\", \"size\": \"mean\"}).reset_index()\n",
    "back_per_rating['Mean Back Clicks number'] = back_per_rating[\"back_nb\"]/back_per_rating[\"size\"]\n",
    "sn.barplot(x=\"rating\", y='Mean Back Clicks number', hue=\"rating\", data=back_per_rating, palette=sn.color_palette('viridis'), ax=ax[0])\n",
    "\n",
    "df_exploded = paths_finished.explode('category')\n",
    "category_back_mean = df_exploded.groupby(['category', 'rating']).size().reset_index(name='size')\n",
    "back_mean = df_exploded.groupby('category')[\"have_back\"].mean().reset_index().sort_values(by='have_back', ascending=False)\n",
    "category_back_mean = category_back_mean.merge(back_mean, on='category').sort_values(by='have_back', ascending=False)\n",
    "category_back_mean['rating_proportion'] = category_back_mean.groupby('category')['size'].transform(lambda x: x / x.sum())\n",
    "\n",
    "order = category_back_mean[\"category\"].unique()\n",
    "base_heights = category_back_mean[['category', 'have_back']].drop_duplicates().set_index('category')['have_back']\n",
    "df_pivot = category_back_mean.pivot(index='category', columns='rating', values='rating_proportion').fillna(0)\n",
    "df_pivot = df_pivot.reindex(order)\n",
    "\n",
    "colors = sn.color_palette('viridis')\n",
    "\n",
    "bottom = pd.Series([0] * len(df_pivot), index=df_pivot.index)\n",
    "for i, rating in enumerate(df_pivot.columns):\n",
    "    ax[1].bar(df_pivot.index, \n",
    "           height=df_pivot[rating] * base_heights,  \n",
    "           bottom=bottom * base_heights,           \n",
    "           label=f'Rating {rating}', \n",
    "           color=colors[i])\n",
    "    bottom += df_pivot[rating]\n",
    "\n",
    "ax[1].set_title('Mean Number of Path with Back Clicks by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Mean Number of Path with Back Clicks')\n",
    "plt.xticks(rotation=90)\n",
    "ax[0].set_title(\"Distribution of Back Clicks per Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that irrespective of the start and end categories, many players path through countries and geography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort games into voyage or not-voyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(df_sm, cmap='BuPu')\n",
    "cbar = fig.colorbar(cax)\n",
    "plt.title('Cosine similarity of article names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voyage_count = (df_finished_voyage['voyage'] == 1).sum() + (df_unfinished_voyage['voyage'] == 1).sum()\n",
    "non_voyage_count = (df_finished_voyage['voyage'] == 0).sum() + (df_unfinished_voyage['voyage'] == 0).sum()\n",
    "print('out of', len(df_finished_voyage)+len(df_unfinished_voyage), 'games : ')\n",
    "print('  - ', voyage_count, ' are voyages')\n",
    "print('  - ', non_voyage_count, ' are not')\n",
    "upper_triangle_indices = np.triu_indices_from(similarity_matrix, k=1) # Flatten the upper triangle of the matrix without the diagonal for sorting\n",
    "\n",
    "# Get the sorted indices for most similar pairs (descending order)\n",
    "sorted_similar_indices = np.argsort(-similarity_matrix[upper_triangle_indices])\n",
    "top_similar_pairs = list(zip(upper_triangle_indices[0][sorted_similar_indices], \n",
    "                             upper_triangle_indices[1][sorted_similar_indices]))\n",
    "\n",
    "print(\"Top 5 most similar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_similar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {similarity_matrix[idx1, idx2]:.4f}\")\n",
    "\n",
    "sorted_dissimilar_indices = np.argsort(similarity_matrix[upper_triangle_indices])\n",
    "top_dissimilar_pairs = list(zip(upper_triangle_indices[0][sorted_dissimilar_indices], \n",
    "                                upper_triangle_indices[1][sorted_dissimilar_indices]))\n",
    "\n",
    "# Print the top 5 most dissimilar pairs\n",
    "print(\"\\nTop 5 most dissimilar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_dissimilar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {similarity_matrix[idx1, idx2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Analysis (Hierarchical Clustering)\n",
    "Find clusters of words that are more similar to each other than to words in other clusters. At the bottom of the tree, most similar pairs are formed, then pairs of pairs are compared and so on. Check out <a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html> this link </a> for more detail and <a href=https://stackoverflow.com/questions/66969893/scipy-and-the-hierarchical-clustering-input> this </a> or <a href=https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial> this link </a> to get a somewhat intuitive idea how how 2D clustering works. The clustering allows to reorder the similarity matrix in a way that regroups articles with high similarity. More analysis needs to be done to understand what the clusters essentially are and represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Mapping for start, voyage, and end nodes\n",
    "df_finished_voyage['start_category_label'] = df_finished_voyage['start_category'].apply(lambda x: 'First in Countries/Geography' if x in ['Countries', 'Geography'] else 'First not in Countries/Geography')\n",
    "df_finished_voyage['end_category_label'] = df_finished_voyage['end_category'].apply(lambda x: 'Target in Countries/Geography' if x in ['Countries', 'Geography'] else 'Target not in Countries/Geography')\n",
    "df_finished_voyage['voyage_label'] = df_finished_voyage['voyage'].apply(lambda x: 'Voyage' if x else 'Non-Voyage')\n",
    "\n",
    "# Count occurrences for each flow from start -> voyage -> end\n",
    "flows = df_finished_voyage.groupby(['start_category_label', 'voyage_label', 'end_category_label']).size().reset_index(name='count')\n",
    "\n",
    "# Define nodes for the Sankey diagram\n",
    "labels = ['First in Countries/Geography', 'First not in Countries/Geography',\n",
    "          'Voyage', 'Non-Voyage',\n",
    "          'Target in Countries/Geography', 'Target not in Countries/Geography']\n",
    "\n",
    "# Create mappings for source and target node indices\n",
    "label_map = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Map flows to Sankey source, target, and value arrays\n",
    "sources = []\n",
    "targets = []\n",
    "values = []\n",
    "\n",
    "for _, row in flows.iterrows():\n",
    "    # Add start -> voyage\n",
    "    sources.append(label_map[row['start_category_label']])\n",
    "    targets.append(label_map[row['voyage_label']])\n",
    "    values.append(row['count'])\n",
    "\n",
    "    # Add voyage -> end\n",
    "    sources.append(label_map[row['voyage_label']])\n",
    "    targets.append(label_map[row['end_category_label']])\n",
    "    values.append(row['count'])\n",
    "\n",
    "\n",
    "node_colors = [\n",
    "    \"rgba(0, 128, 128, 0.6)\",  \"rgba(244,109,67,0.8)\",   \n",
    "    \"rgba(0, 128, 128, 0.6)\",  \"rgba(244,109,67,0.8)\",   \n",
    "    \"rgba(0, 128, 128, 0.6)\",  \"rgba(244,109,67,0.8)\"\n",
    "    ]\n",
    "\n",
    "link_colors = [\n",
    "    \"rgba(146,197,222,0.6)\",  \"rgba(244,109,67,0.6)\",   \n",
    "    \"rgba(146,197,222,0.6)\",  \"rgba(244,109,67,0.6)\",   \n",
    "    \"rgba(146,197,222,0.6)\",  \"rgba(244,109,67,0.6)\"\n",
    "    ]\n",
    "\n",
    "# Create the Sankey plot\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(pad=15, thickness=20, line=dict(color=\"white\", width=0.1), label=labels, color=node_colors),\n",
    "    link=dict(source=sources, target=targets, value=values)\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Path classification as Voyage or not\",\n",
    "    font_size=10,\n",
    "    title_font_size=14,\n",
    "    title_x=0.5,\n",
    "    plot_bgcolor=\"white\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, leaves_list\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "sm = df_sm.to_numpy()\n",
    "linkage_matrix = linkage(sm, method='ward')\n",
    "ordered_indices = leaves_list(linkage_matrix)\n",
    "reordered_matrix = sm[ordered_indices, :][:, ordered_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(reordered_matrix, cmap='BuPu')\n",
    "plt.title('Reordered Similarity Matrix')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define the initial threshold\n",
    "initial_threshold = 0.5\n",
    "\n",
    "# Function to plot the binary matrix based on a given threshold\n",
    "def plot_thresholded_matrix(threshold):\n",
    "    # Create a binary mask with the current threshold\n",
    "    binary_matrix = np.where(reordered_matrix >= threshold, 1, 0)\n",
    "    \n",
    "    # Plot the binary matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(binary_matrix, cmap='Reds', interpolation='nearest')\n",
    "    plt.title(f'Reordered Similarity Matrix (Threshold = {threshold:.2f})')\n",
    "    plt.colorbar(label='Above Threshold (1 = Red, 0 = White)')\n",
    "    plt.show()\n",
    "\n",
    "# Create the interactive slider\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=initial_threshold,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description='Threshold:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Display the slider and link it to the plotting function\n",
    "output = widgets.interactive_output(plot_thresholded_matrix, {'threshold': threshold_slider})\n",
    "display(threshold_slider, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_triangle_indices = np.triu_indices_from(sm, k=1) # Flatten the upper triangle of the matrix without the diagonal for sorting\n",
    "\n",
    "# Get the sorted indices for most similar pairs (descending order)\n",
    "sorted_similar_indices = np.argsort(-sm[upper_triangle_indices])\n",
    "top_similar_pairs = list(zip(upper_triangle_indices[0][sorted_similar_indices], \n",
    "                             upper_triangle_indices[1][sorted_similar_indices]))\n",
    "\n",
    "print(\"Top 5 most similar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_similar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {sm[idx1, idx2]:.4f}\")\n",
    "\n",
    "sorted_dissimilar_indices = np.argsort(sm[upper_triangle_indices])\n",
    "top_dissimilar_pairs = list(zip(upper_triangle_indices[0][sorted_dissimilar_indices], \n",
    "                                upper_triangle_indices[1][sorted_dissimilar_indices]))\n",
    "\n",
    "# Print the top 5 most dissimilar pairs\n",
    "print(\"\\nTop 5 most dissimilar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_dissimilar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {sm[idx1, idx2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The reordered article indices make intuitive sense, similar words are regrouped')\n",
    "print(df_article_names[ordered_indices].iloc[1995:2005])\n",
    "print(df_article_names[ordered_indices].iloc[450:460])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of similarity on paths\n",
    "find similarity on geo vs non-geo paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_finished_paths = [replace_back_clicks(path).split(';') for path in df_finished['path'].tolist()]\n",
    "path_similarities = []\n",
    "\n",
    "for path in all_finished_paths:\n",
    "    path_similarity = []\n",
    "    for step in range(len(path)-1):\n",
    "        current, next = path[step], path[step+1]\n",
    "        path_similarity.append(df_sm[current][next])\n",
    "\n",
    "    path_similarities.append(path_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_id = 1829\n",
    "path = path_similarities[path_id]\n",
    "plt.plot(range(len(path)), path, marker='o')\n",
    "plt.xticks([i-0.5 for i in range(len(path)+1)], all_finished_paths[path_id], rotation=90)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_N_path_similarity = {}\n",
    "for path_sim in path_similarities:\n",
    "    path_length = len(path_sim)\n",
    "    len_N_path_similarity.setdefault(path_length, []).append(path_sim)\n",
    "\n",
    "len_N_mean_similarity = {paths_len: np.mean(paths, axis=0) for paths_len, paths in len_N_path_similarity.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "for i in range(1, 11):\n",
    "    sn.lineplot(len_N_mean_similarity[i+1], lw=1, label=i)\n",
    "plt.legend(title='# Link Clicks')\n",
    "plt.xlabel(\"Position of the Click in the Players' Paths\")\n",
    "plt.ylabel('Mean Semantic Similarity')\n",
    "plt.title('Mean Semantic Similarity Difference Aggregated by Path Lenghts')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### html Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_articles = parser.article_names # The html articles in the data\n",
    "df_article_names = read_articles() # The articles used in the paths-and-graph data\n",
    "intersect = pd.merge(df_html_articles, df_article_names, how='inner', on=\"article\")\n",
    "print(f'There are {len(df_article_names)} articles in the paths-and-graph data and {len(intersect)} of those are in the html articles.')\n",
    "difference = df_html_articles[~df_html_articles.isin(df_article_names)]\n",
    "print(f'This means there are {len(difference)} articles more in the html data, such as \"{difference.iloc[0]}\", \"{difference.iloc[5]}\" or \"{difference.iloc[10]}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parser.parse_html_article(parser.article_URLs[266])\n",
    "if parsed: parser.get_overview(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "sort_column = widgets.Dropdown(\n",
    "    options=df_html_stats.columns,\n",
    "    value='total_words',\n",
    "    description='Sort by:'\n",
    ")\n",
    "\n",
    "n_slider = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Number (n):'\n",
    ")\n",
    "\n",
    "# Display function to update table based on widget values\n",
    "def display_sorted(n, sort_by):\n",
    "    sorted_df = df_html_stats.sort_values(by=sort_by, ascending=False)\n",
    "    top_n = sorted_df.head(n)\n",
    "    bottom_n = sorted_df.tail(n)\n",
    "    \n",
    "    print(f\"\\nTop {n} Articles by {sort_by}:\")\n",
    "    display(top_n)\n",
    "    print(f\"\\nBottom {n} Articles by {sort_by}:\")\n",
    "    display(bottom_n)\n",
    "\n",
    "# Link widgets to display function\n",
    "widgets.interactive(display_sorted, n=n_slider, sort_by=sort_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# David Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import *\n",
    "import plotly.graph_objects as go\n",
    "from src.helpers import *\n",
    "from src.network_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished = read_finished_paths()\n",
    "df_unfinished = read_unfinished_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = read_categories()\n",
    "labels, parents, values, ids = create_treemap_data(df_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the treemap\n",
    "fig = go.Figure(go.Treemap(\n",
    "    labels=labels,\n",
    "    parents=parents,\n",
    "    values=values,\n",
    "    ids=ids,\n",
    "    #textinfo=\"label+value\",  # Show both label and value\n",
    "    textfont=dict(size=18),  # Increase font size; will automatically fit smaller labels\n",
    "\n",
    "))\n",
    "fig.update_layout(margin=dict(t=50, l=25, r=25, b=25), title=\"Category Distribution in Articles (Some articles have multiple categories, thus the sum of values is greater than the number of articles)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assing to articles with multiples categories the most specific category (category with less articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "labels_filtered, parents_filtered, values_filtered, ids_filtered = create_treemap_data(df_categories_filtered)\n",
    "\n",
    "# Plotting the treemap\n",
    "fig = go.Figure(go.Treemap(\n",
    "    labels=labels_filtered,\n",
    "    parents=parents_filtered,\n",
    "    values=values_filtered,\n",
    "    ids=ids_filtered,\n",
    "    textfont=dict(size=18),  # Increase font size; will automatically fit smaller labels\n",
    "))\n",
    "\n",
    "fig.update_layout(margin=dict(t=50, l=25, r=25, b=25), title=\"Category Distribution in Articles (Only the most specific category is shown for each article)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common paths of transitions between categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigation within the same category (not merged)\n",
    "\n",
    "Example :\n",
    "- Science -> Science -> Science\n",
    "- Science -> Science -> Science -> Citizenship -> Design and Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_paths_f = analyze_categories_paths(df_finished, df_categories_filtered, omit_loops=False)\n",
    "common_paths_u = analyze_categories_paths(df_unfinished, df_categories_filtered, omit_loops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data = get_position_frequencies(common_paths_f, max_position=15)\n",
    "plot_position_line(df_position_data, title=\"Position Frequencies for Finished Paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalized_position_bar(df_position_data, title=\"Normalized Position Frequencies for Finished Paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data = get_position_frequencies(common_paths_u, max_position=15)\n",
    "plot_position_line(df_position_data, title=\"Position Frequencies for Unfinished Paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigation with only change of category  (merged)\n",
    "\n",
    "Example :\n",
    "- Science -> Science -> Science **become** Science\n",
    "- Science -> Science -> Science -> Citizenship -> Design and Technology **become** Science -> Citizenship -> Design and Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_paths_f_nl = analyze_categories_paths(df_finished, df_categories_filtered, omit_loops=True)\n",
    "common_paths_u_nl = analyze_categories_paths(df_unfinished, df_categories_filtered, omit_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data = get_position_frequencies(common_paths_f_nl, max_position=15)\n",
    "plot_position_line(df_position_data, title=\"Position Frequencies for Finished Paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data = get_position_frequencies(common_paths_u_nl, max_position=15)\n",
    "plot_position_line(df_position_data, title=\"Position Frequencies for Unfinished Paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished = read_finished_paths()\n",
    "df_unfinished = read_unfinished_paths()\n",
    "df_categories = read_categories()   \n",
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "\n",
    "df_finished['path'] = df_finished['path'].apply(replace_back_clicks)\n",
    "df_unfinished['path'] = df_unfinished['path'].apply(replace_back_clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_abbreviations = {\n",
    "    'Art': 'Art',\n",
    "    'Mathematics': 'Math',\n",
    "    'IT': 'IT',\n",
    "    'Business Studies': 'BS',\n",
    "    'Music': 'Music',\n",
    "    'Religion': 'R',\n",
    "    'Language and literature': 'L&L',\n",
    "    'Citizenship': 'CIT',\n",
    "    'Countries': 'C',\n",
    "    'Design and Technology': 'D&T',\n",
    "    'Everyday life': 'Life',\n",
    "    'History': 'Hist',\n",
    "    'People': 'P',\n",
    "    'Geography': 'Geo',\n",
    "    'Science': 'Sci'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_network(df_finished, df_categories_filtered, include_self_loops=False)\n",
    "\n",
    "plot_network(G, title=\"Networks of transition whithin Categoires (exclude self loops)\", show_edge_labels=False, node_size=1000, node_abbreviations=category_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_normalized = normalize_edge_weights(G, df_categories_filtered)\n",
    "plot_network(G_normalized, title=\"Networks normalize by the category size of the source node (exclude self loops)\", show_edge_labels=False, node_size=1000, node_abbreviations=category_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_edge_weights(G_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adjacency_matrix(G):\n",
    "\n",
    "    adj_matrix = nx.to_pandas_adjacency(G, weight='weight')\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Create a mask for zero values\n",
    "    mask = adj_matrix == 0\n",
    "    # Plot with a diverging color map and mask for zero values\n",
    "    sn.heatmap(adj_matrix, cmap='YlGnBu', mask=mask, annot=True, fmt='0.1f', cbar_kws={'label': 'Transition Weight', 'shrink': 0.8},\n",
    "                linewidths=0.5, linecolor='grey', vmin=adj_matrix.values.min(), vmax=adj_matrix.values.max(), square=True)\n",
    "    plt.title(\"Adjacency Matrix of Category Transitions\")\n",
    "    plt.xlabel(\"Target Category\")\n",
    "    plt.ylabel(\"Source Category\")\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.show()\n",
    "\n",
    "plot_adjacency_matrix(G_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
