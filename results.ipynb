{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import *\n",
    "from src.helpers import *\n",
    "from src.htmlParser import htmlParser\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = htmlParser()\n",
    "parser.load_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: blablal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A- Data Cleaning\n",
    "\n",
    "- Steps done in data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_names = read_articles() \n",
    "df_html_stats = parser.get_df_html_stats()\n",
    "df_categories = read_categories()\n",
    "df_links = read_links()\n",
    "df_shortest_path = read_shortest_path_matrix()\n",
    "df_unfinished = read_unfinished_paths()\n",
    "df_finished = read_finished_paths() \n",
    "df_sm = read_similartiy_matrix() \n",
    "df_scat = read_categories_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B- Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add some useful metrics to each paths dataframe: shortest path, semantic similarity\n",
    "df_unfinished['cosine_similarity'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_unfinished['shortest_path'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_unfinished['path_length'] = df_unfinished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_unfinished['back_clicks'] = df_unfinished['path'].apply(lambda x: x.count('<'))\n",
    "df_unfinished[\"categories_similarity\"] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)\n",
    "\n",
    "df_finished['cosine_similarity'] = df_finished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_finished['shortest_path'] = df_finished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_finished['path_length'] = df_finished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_finished['back_clicks'] = df_finished['path'].apply(lambda x: x.count('<'))\n",
    "df_finished[\"categories_similarity\"] = df_finished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: -1 with no errorbar makes no sense. 1 with no error bar makes sense (trivial case where start=target and similarity with itself=1)\n",
    "\n",
    "df_finished_clean = df_finished[df_finished['shortest_path'] != 0].copy()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished_clean, x='shortest_path', y='cosine_similarity')\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='cosine_similarity')\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean cosine similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def calculate_correlations_with_shortestPath(df, column_name):\n",
    "    # Ensure 'shortest_path' is numeric\n",
    "    df['shortest_path'] = df['shortest_path'].astype(float)\n",
    "\n",
    "    pearson_corr, pearson_p = pearsonr(df['shortest_path'], df[column_name])\n",
    "    spearman_corr, spearman_p = spearmanr(df['shortest_path'], df[column_name])\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Pearson correlation: {pearson_corr:.4f}, p-value: {pearson_p:.4e}\")\n",
    "    print(f\"Spearman correlation: {spearman_corr:.4f}, p-value: {spearman_p:.4e}\")\n",
    "\n",
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished_clean,\"cosine_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"cosine_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: -1 with no errorbar makes no sense. 1 with no error bar makes sense (trivial case where start=target and similarity with itself=1)\n",
    "# impossible paths in unfinishes paths are possible however. check if it is sound though because of the previous problem.\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished_clean, x='shortest_path', y='categories_similarity')\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='categories_similarity')\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean categories_similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished_clean,\"categories_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"categories_similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pearson Correlation\n",
    "Measures the linear relationship between two continuous variables.\n",
    "\n",
    "- Spearman Correlation\n",
    "Assesses the monotonic relationship using ranked data, making it less sensitive to outliers and non-linear relationships.\n",
    "\n",
    "The p-values are effectively zero, which is highly significant statistically. This suggests that the observed correlations are unlikely to be due to random chance.\n",
    "\n",
    "-> Thus as the distance path increase, the cosine_similarity decrease\n",
    "In other words..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulty measure\n",
    "Find patterns in user behaviour and try to understand how we could measure whether a game was difficult or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean duration of finished paths is {df_finished['durationInSec'].mean():.0f} seconds\")\n",
    "print(f\"The mean duration of unfinished paths is {df_unfinished['durationInSec'].mean():.0f} seconds\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax1 = plt.subplot(121)\n",
    "sn.histplot(df_unfinished, x='durationInSec', hue='type', bins=75)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of game duration for unfinished games')\n",
    "\n",
    "plt.subplot(122, sharey = ax1)\n",
    "sn.histplot(df_finished, x='durationInSec', bins=75, alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of game duration for finished games')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_stats_duration = pd.DataFrame()\n",
    "df_path_stats_duration['mean'] = df_finished.groupby('rating', dropna=False)['durationInSec'].mean()\n",
    "df_path_stats_duration['std'] = df_finished.groupby('rating', dropna=False)['durationInSec'].std()\n",
    "df_path_stats_duration['sem'] = df_finished.groupby('rating', dropna=False)['durationInSec'].sem()\n",
    "\n",
    "df_path_stats_length = pd.DataFrame()\n",
    "df_path_stats_length['mean'] = df_finished.groupby('rating', dropna=False)['path_length'].mean()\n",
    "df_path_stats_length['std'] = df_finished.groupby('rating', dropna=False)['path_length'].std()\n",
    "df_path_stats_length['sem'] = df_finished.groupby('rating', dropna=False)['path_length'].sem()\n",
    "\n",
    "df_path_stats = pd.concat([df_path_stats_duration, df_path_stats_length], axis=1, keys=['duration', 'length'])\n",
    "\n",
    "df_path_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those are some nice log-normal distributions -> are they though? the distribution is normal in loglog, not log. MAYBE POWER LAW IDK\n",
    "# except for NaN, there is a steady increase of the path duration mean when rating goes up\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "means, stds = [], []\n",
    "ax1 = plt.subplot(231)\n",
    "sn.histplot(df_finished[df_finished['rating'].isnull()], x='durationInSec', bins=50) # change x to x = 'path_length' for path length\n",
    "plt.axvline(df_finished[df_finished['rating'].isnull()]['durationInSec'].mean(), color='red')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('NaN')\n",
    "\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(231+i, sharex = ax1, sharey=ax1)\n",
    "    sn.histplot(df_finished[df_finished['rating']==i], x='durationInSec', bins=50)\n",
    "    plt.axvline(df_finished[df_finished['rating']==i]['durationInSec'].mean(), color='red')\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.title(i)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Path duration by rating', y=1.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "sn.histplot(df_finished, x='path_length', bins=50)\n",
    "plt.yscale('log')\n",
    "plt.xlim(0, 120)\n",
    "\n",
    "plt.subplot(122)\n",
    "sn.histplot(df_finished, x='back_clicks', bins=50)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories distribution in start and end paths between finished and unfinished games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished = find_categories_start_end(df_finished, df_categories)\n",
    "paths_unfinished = find_categories_start_end(df_unfinished, df_categories)\n",
    "\n",
    "paths_finished[\"finished\"] = 1\n",
    "paths_unfinished[\"finished\"] = 0\n",
    "\n",
    "paths = pd.concat([paths_finished, paths_unfinished], join='inner')\n",
    "paths_melted = paths.melt(\n",
    "    id_vars=[\"finished\"],\n",
    "    value_vars=[\"start_category\", \"end_category\"],\n",
    "    var_name=\"category_type\",\n",
    "    value_name=\"category\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color palette based on unique categories\n",
    "unique_categories = paths_melted['category'].unique()\n",
    "palette = sn.color_palette(\"Set1\", n_colors=len(unique_categories))\n",
    "color_mapping = dict(zip(unique_categories, palette))\n",
    "\n",
    "g = sn.FacetGrid(\n",
    "    data=paths_melted,\n",
    "    col=\"finished\",\n",
    "    row=\"category_type\",\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    "    margin_titles=True,\n",
    "    height=4,\n",
    ")\n",
    "\n",
    "g.map_dataframe(\n",
    "    sn.countplot,\n",
    "    x=\"category\",\n",
    "    hue=\"category\",\n",
    "    palette=color_mapping,\n",
    "    order=paths_melted['category'].value_counts().index  # Order by frequency\n",
    ")\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "for ax in g.axes.flatten():\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of duration of path between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='durationInSec', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='durationInSec',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='BuPu', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of Duration (seconds) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of length of path between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished[\"steps_count\"] = paths_finished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "paths_unfinished[\"steps_count\"] = paths_unfinished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='steps_count', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='steps_count',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='BuPu', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of length of path (number of steps) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of rating between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='rating', \n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu')\n",
    "plt.title(\"Heatmap of rating for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the rating, the backclick number and the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "paths_finished = extract_category_path(df_finished, df_categories_filtered)\n",
    "paths_finished = backtrack(paths_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "back_per_rating = paths_finished.groupby(\"rating\").agg({\"back_nb\": \"mean\", \"size\": \"mean\"}).reset_index()\n",
    "back_per_rating['Mean Back Clicks number'] = back_per_rating[\"back_nb\"]/back_per_rating[\"size\"]\n",
    "sn.barplot(x=\"rating\", y='Mean Back Clicks number', hue=\"rating\", data=back_per_rating, palette=sn.color_palette('viridis'), ax=ax[0])\n",
    "\n",
    "df_exploded = paths_finished.explode('category')\n",
    "category_back_mean = df_exploded.groupby(['category', 'rating']).size().reset_index(name='size')\n",
    "back_mean = df_exploded.groupby('category')[\"have_back\"].mean().reset_index().sort_values(by='have_back', ascending=False)\n",
    "category_back_mean = category_back_mean.merge(back_mean, on='category').sort_values(by='have_back', ascending=False)\n",
    "category_back_mean['rating_proportion'] = category_back_mean.groupby('category')['size'].transform(lambda x: x / x.sum())\n",
    "\n",
    "order = category_back_mean[\"category\"].unique()\n",
    "base_heights = category_back_mean[['category', 'have_back']].drop_duplicates().set_index('category')['have_back']\n",
    "df_pivot = category_back_mean.pivot(index='category', columns='rating', values='rating_proportion').fillna(0)\n",
    "df_pivot = df_pivot.reindex(order)\n",
    "\n",
    "colors = sn.color_palette('viridis')\n",
    "\n",
    "bottom = pd.Series([0] * len(df_pivot), index=df_pivot.index)\n",
    "for i, rating in enumerate(df_pivot.columns):\n",
    "    ax[1].bar(df_pivot.index, \n",
    "           height=df_pivot[rating] * base_heights,  \n",
    "           bottom=bottom * base_heights,           \n",
    "           label=f'Rating {rating}', \n",
    "           color=colors[i])\n",
    "    bottom += df_pivot[rating]\n",
    "\n",
    "ax[1].set_title('Mean Number of Path with Back Clicks by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Mean Number of Path with Back Clicks')\n",
    "plt.xticks(rotation=90)\n",
    "ax[0].set_title(\"Distribution of Back Clicks per Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that irrespective of the start and end categories, many players path through countries and geography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort categories paths into voyage or not voyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#david preprocessing  \n",
    "df_finished = df_finished.loc[~df_finished['path'].str.contains('Pikachu'), :]\n",
    "df_unfinished = df_unfinished.loc[~df_unfinished['target'].str.contains('Pikachu'), :]\n",
    "df_unfinished = df_unfinished.loc[~df_unfinished['path'].str.contains('Pikachu'), :]\n",
    "# one category per article \n",
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "#Science->Science->Science  become  Science\n",
    "common_paths_f_nl = analyze_categories_paths(df_finished, df_categories_filtered, omit_loops=True)\n",
    "common_paths_u_nl = analyze_categories_paths(df_unfinished, df_categories_filtered, omit_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_voyage_status(common_paths_f_nl.loc[2]['Category Path'], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort paths into voyage and not voyage\n",
    "common_paths_f_nl = voyage_sorting_category_path(common_paths_f_nl,1,2)\n",
    "common_paths_u_nl = voyage_sorting_category_path(common_paths_u_nl,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity\n",
    "An interesting way to figure out how players move through the wikispeedia network is semantic similarity. This encompasses both categories similarity and the abstract notion of \"meaning\". To concretise this notion, we consider two different measures of similarity: \n",
    "\n",
    "Find clusters of words that are more similar to each other than to words in other clusters. The clustering allows to reorder the similarity matrix in a way that regroups articles with high similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "sm = df_sm.to_numpy()\n",
    "linkage_matrix = linkage(sm, method='ward')\n",
    "ordered_indices = leaves_list(linkage_matrix)\n",
    "reordered_matrix = sm[ordered_indices, :][:, ordered_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(reordered_matrix, cmap='BuPu')\n",
    "plt.title('Reordered Similarity Matrix')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define the initial threshold\n",
    "initial_threshold = 0.5\n",
    "\n",
    "# Function to plot the binary matrix based on a given threshold\n",
    "def plot_thresholded_matrix(threshold):\n",
    "    # Create a binary mask with the current threshold\n",
    "    binary_matrix = np.where(reordered_matrix >= threshold, 1, 0)\n",
    "    \n",
    "    # Plot the binary matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(binary_matrix, cmap='Reds', interpolation='nearest')\n",
    "    plt.title(f'Reordered Similarity Matrix (Threshold = {threshold:.2f})')\n",
    "    plt.colorbar(label='Above Threshold (1 = Red, 0 = White)')\n",
    "    plt.show()\n",
    "\n",
    "# Create the interactive slider\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=initial_threshold,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description='Threshold:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Display the slider and link it to the plotting function\n",
    "output = widgets.interactive_output(plot_thresholded_matrix, {'threshold': threshold_slider})\n",
    "display(threshold_slider, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_triangle_indices = np.triu_indices_from(sm, k=1) # Flatten the upper triangle of the matrix without the diagonal for sorting\n",
    "\n",
    "# Get the sorted indices for most similar pairs (descending order)\n",
    "sorted_similar_indices = np.argsort(-sm[upper_triangle_indices])\n",
    "top_similar_pairs = list(zip(upper_triangle_indices[0][sorted_similar_indices], \n",
    "                             upper_triangle_indices[1][sorted_similar_indices]))\n",
    "\n",
    "print(\"Top 5 most similar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_similar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {sm[idx1, idx2]:.4f}\")\n",
    "\n",
    "sorted_dissimilar_indices = np.argsort(sm[upper_triangle_indices])\n",
    "top_dissimilar_pairs = list(zip(upper_triangle_indices[0][sorted_dissimilar_indices], \n",
    "                                upper_triangle_indices[1][sorted_dissimilar_indices]))\n",
    "\n",
    "# Print the top 5 most dissimilar pairs\n",
    "print(\"\\nTop 5 most dissimilar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_dissimilar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {sm[idx1, idx2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The reordered article indices make intuitive sense, similar words are regrouped')\n",
    "print(df_article_names[ordered_indices].iloc[1995:2005])\n",
    "print(df_article_names[ordered_indices].iloc[450:460])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of similarity on paths\n",
    "find similarity on geo vs non-geo paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_finished_paths = [replace_back_clicks(path).split(';') for path in df_finished['path'].tolist()]\n",
    "path_similarities = []\n",
    "\n",
    "for path in all_finished_paths:\n",
    "    path_similarity = []\n",
    "    for step in range(len(path)-1):\n",
    "        current, next = path[step], path[step+1]\n",
    "        path_similarity.append(df_sm[current][next])\n",
    "\n",
    "    path_similarities.append(path_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_id = 1829\n",
    "path = path_similarities[path_id]\n",
    "plt.plot(range(len(path)), path, marker='o')\n",
    "plt.xticks([i-0.5 for i in range(len(path)+1)], all_finished_paths[path_id], rotation=90)\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_N_path_similarity = {}\n",
    "for path_sim in path_similarities:\n",
    "    path_length = len(path_sim)\n",
    "    len_N_path_similarity.setdefault(path_length, []).append(path_sim)\n",
    "\n",
    "len_N_mean_similarity = {paths_len: np.mean(paths, axis=0) for paths_len, paths in len_N_path_similarity.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "for i in range(1, 11):\n",
    "    sn.lineplot(len_N_mean_similarity[i+1], lw=1, label=i)\n",
    "plt.legend(title='# Link Clicks')\n",
    "plt.xlabel(\"Position of the Click in the Players' Paths\")\n",
    "plt.ylabel('Mean Semantic Similarity')\n",
    "plt.title('Mean Semantic Similarity Difference Aggregated by Path Lenghts')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### html Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_articles = parser.article_names # The html articles in the data\n",
    "df_article_names = read_articles() # The articles used in the paths-and-graph data\n",
    "intersect = pd.merge(df_html_articles, df_article_names, how='inner', on=\"article\")\n",
    "print(f'There are {len(df_article_names)} articles in the paths-and-graph data and {len(intersect)} of those are in the html articles.')\n",
    "difference = df_html_articles[~df_html_articles.isin(df_article_names)]\n",
    "print(f'This means there are {len(difference)} articles more in the html data, such as \"{difference.iloc[0]}\", \"{difference.iloc[5]}\" or \"{difference.iloc[10]}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parser.parse_html_article(parser.article_URLs[266])\n",
    "if parsed: parser.get_overview(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "sort_column = widgets.Dropdown(\n",
    "    options=df_html_stats.columns,\n",
    "    value='total_words',\n",
    "    description='Sort by:'\n",
    ")\n",
    "\n",
    "n_slider = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Number (n):'\n",
    ")\n",
    "\n",
    "# Display function to update table based on widget values\n",
    "def display_sorted(n, sort_by):\n",
    "    sorted_df = df_html_stats.sort_values(by=sort_by, ascending=False)\n",
    "    top_n = sorted_df.head(n)\n",
    "    bottom_n = sorted_df.tail(n)\n",
    "    \n",
    "    print(f\"\\nTop {n} Articles by {sort_by}:\")\n",
    "    display(top_n)\n",
    "    print(f\"\\nBottom {n} Articles by {sort_by}:\")\n",
    "    display(bottom_n)\n",
    "\n",
    "# Link widgets to display function\n",
    "widgets.interactive(display_sorted, n=n_slider, sort_by=sort_column)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
