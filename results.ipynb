{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import *\n",
    "from src.helpers import *\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = htmlParser()\n",
    "parser.load_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: blablal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A- Data Cleaning\n",
    "\n",
    "- Steps done in data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_names = read_articles() \n",
    "df_html_stats = parser.get_df_html_stats()\n",
    "df_categories = read_categories()\n",
    "df_links = read_links()\n",
    "df_shortest_path = read_shortest_path_matrix()\n",
    "df_unfinished = read_unfinished_paths()\n",
    "df_finished = read_finished_paths() \n",
    "df_sm = read_similartiy_matrix() \n",
    "df_scat = read_categories_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B- Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add some useful metrics to each paths dataframe: shortest path, semantic similarity\n",
    "df_unfinished['cosine_similarity'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_unfinished['shortest_path'] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_unfinished['path_length'] = df_unfinished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_unfinished['back_clicks'] = df_unfinished['path'].apply(lambda x: x.count('<'))\n",
    "df_unfinished[\"categories_similarity\"] = df_unfinished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)\n",
    "\n",
    "df_finished['cosine_similarity'] = df_finished.apply(lambda x: find_shortest_distance(x, df_sm), axis=1)\n",
    "df_finished['shortest_path'] = df_finished.apply(lambda x: find_shortest_distance(x, df_shortest_path), axis=1)\n",
    "df_finished['path_length'] = df_finished['path'].apply(lambda x: x.count(';') + 1)\n",
    "df_finished['back_clicks'] = df_finished['path'].apply(lambda x: x.count('<'))\n",
    "df_finished[\"categories_similarity\"] = df_finished.apply(lambda x: find_shortest_distance(x, df_scat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: -1 with no errorbar makes no sense. 1 with no error bar makes sense (trivial case where start=target and similarity with itself=1)\n",
    "\n",
    "df_finished_clean = df_finished[df_finished['shortest_path'] != 0].copy()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished_clean, x='shortest_path', y='cosine_similarity')\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='cosine_similarity')\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean cosine similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def calculate_correlations_with_shortestPath(df, column_name):\n",
    "    # Ensure 'shortest_path' is numeric\n",
    "    df['shortest_path'] = df['shortest_path'].astype(float)\n",
    "\n",
    "    pearson_corr, pearson_p = pearsonr(df['shortest_path'], df[column_name])\n",
    "    spearman_corr, spearman_p = spearmanr(df['shortest_path'], df[column_name])\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Pearson correlation: {pearson_corr:.4f}, p-value: {pearson_p:.4e}\")\n",
    "    print(f\"Spearman correlation: {spearman_corr:.4f}, p-value: {spearman_p:.4e}\")\n",
    "\n",
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished_clean,\"cosine_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"cosine_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: -1 with no errorbar makes no sense. 1 with no error bar makes sense (trivial case where start=target and similarity with itself=1)\n",
    "# impossible paths in unfinishes paths are possible however. check if it is sound though because of the previous problem.\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.subplot(121)\n",
    "sn.barplot(data=df_finished_clean, x='shortest_path', y='categories_similarity')\n",
    "plt.title('Finished paths')\n",
    "\n",
    "plt.subplot(122, sharey=ax)\n",
    "sn.barplot(data=df_unfinished, x='shortest_path', y='categories_similarity')\n",
    "plt.title('Unfinished paths')\n",
    "\n",
    "plt.suptitle('Mean categories_similarity per shortest path length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished paths:')\n",
    "finished_results = calculate_correlations_with_shortestPath(df_finished_clean,\"categories_similarity\")\n",
    "print('\\nUnfinished paths:')\n",
    "unfinished_results = calculate_correlations_with_shortestPath(df_unfinished,\"categories_similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pearson Correlation\n",
    "Measures the linear relationship between two continuous variables.\n",
    "\n",
    "- Spearman Correlation\n",
    "Assesses the monotonic relationship using ranked data, making it less sensitive to outliers and non-linear relationships.\n",
    "\n",
    "The p-values are effectively zero, which is highly significant statistically. This suggests that the observed correlations are unlikely to be due to random chance.\n",
    "\n",
    "-> Thus as the distance path increase, the cosine_similarity decrease\n",
    "In other words..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulty measure\n",
    "Find patterns in user behaviour and try to understand how we could measure whether a game was difficult or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean duration of finished paths is {df_finished['durationInSec'].mean():.0f} seconds\")\n",
    "print(f\"The mean duration of unfinished paths is {df_unfinished['durationInSec'].mean():.0f} seconds\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax1 = plt.subplot(121)\n",
    "sn.histplot(df_unfinished, x='durationInSec', hue='type', bins=75)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of game duration for unfinished games')\n",
    "\n",
    "plt.subplot(122, sharey = ax1)\n",
    "sn.histplot(df_finished, x='durationInSec', bins=75, alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.title('Histogram of game duration for finished games')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_stats_duration = pd.DataFrame()\n",
    "df_path_stats_duration['mean'] = df_finished.groupby('rating', dropna=False)['durationInSec'].mean()\n",
    "df_path_stats_duration['std'] = df_finished.groupby('rating', dropna=False)['durationInSec'].std()\n",
    "df_path_stats_duration['sem'] = df_finished.groupby('rating', dropna=False)['durationInSec'].sem()\n",
    "\n",
    "df_path_stats_length = pd.DataFrame()\n",
    "df_path_stats_length['mean'] = df_finished.groupby('rating', dropna=False)['path_length'].mean()\n",
    "df_path_stats_length['std'] = df_finished.groupby('rating', dropna=False)['path_length'].std()\n",
    "df_path_stats_length['sem'] = df_finished.groupby('rating', dropna=False)['path_length'].sem()\n",
    "\n",
    "df_path_stats = pd.concat([df_path_stats_duration, df_path_stats_length], axis=1, keys=['duration', 'length'])\n",
    "\n",
    "df_path_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those are some nice log-normal distributions -> are they though? the distribution is normal in loglog, not log.\n",
    "# except for NaN, there is a steady increase of the path duration mean when rating goes up\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "means, stds = [], []\n",
    "ax1 = plt.subplot(231)\n",
    "sn.histplot(df_finished[df_finished['rating'].isnull()], x='durationInSec', bins=50) # change x to x = 'path_length' for path length\n",
    "means.append(df_finished[df_finished['rating'].isnull()]['durationInSec'].mean())\n",
    "stds.append(df_finished[df_finished['rating'].isnull()]['durationInSec'].std())\n",
    "plt.axvline(means[0], color='red')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.title('NaN')\n",
    "\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(231+i, sharex = ax1, sharey=ax1)\n",
    "    means.append(df_finished[df_finished['rating']==i]['durationInSec'].mean())\n",
    "    stds.append(df_finished[df_finished['rating']==i]['durationInSec'].std())\n",
    "    sn.histplot(df_finished[df_finished['rating']==i], x='durationInSec', bins=50)\n",
    "    plt.axvline(means[i], color='red')\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.title(i)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Path duration by rating', y=1.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "sn.histplot(df_finished, x='path_length', bins=50)\n",
    "plt.yscale('log')\n",
    "plt.xlim(0, 120)\n",
    "\n",
    "plt.subplot(122)\n",
    "sn.histplot(df_finished, x='back_clicks', bins=50)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories distribution in start and end paths between finished and unfinished games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished = find_categories_start_end(df_finished, df_categories)\n",
    "paths_unfinished = find_categories_start_end(df_unfinished, df_categories)\n",
    "\n",
    "paths_finished[\"finished\"] = 1\n",
    "paths_unfinished[\"finished\"] = 0\n",
    "\n",
    "paths = pd.concat([paths_finished, paths_unfinished], join='inner')\n",
    "paths_melted = paths.melt(\n",
    "    id_vars=[\"finished\"],\n",
    "    value_vars=[\"start_category\", \"end_category\"],\n",
    "    var_name=\"category_type\",\n",
    "    value_name=\"category\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color palette based on unique categories\n",
    "unique_categories = paths_melted['category'].unique()\n",
    "palette = sn.color_palette(\"Set1\", n_colors=len(unique_categories))\n",
    "color_mapping = dict(zip(unique_categories, palette))\n",
    "\n",
    "g = sn.FacetGrid(\n",
    "    data=paths_melted,\n",
    "    col=\"finished\",\n",
    "    row=\"category_type\",\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    "    margin_titles=True,\n",
    "    height=4,\n",
    ")\n",
    "\n",
    "g.map_dataframe(\n",
    "    sn.countplot,\n",
    "    x=\"category\",\n",
    "    hue=\"category\",\n",
    "    palette=color_mapping,\n",
    "    order=paths_melted['category'].value_counts().index  # Order by frequency\n",
    ")\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "for ax in g.axes.flatten():\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of duration of path between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='durationInSec', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='durationInSec',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='BuPu', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of Duration (seconds) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of length of path between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_finished[\"steps_count\"] = paths_finished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "paths_unfinished[\"steps_count\"] = paths_unfinished[\"path\"].apply(lambda x: len(x.split(\";\")))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='steps_count', \n",
    "                                                    aggfunc='mean')\n",
    "path_unfinished_length_categories = paths_unfinished.pivot_table(index='start_category',\n",
    "                                                    columns='end_category',\n",
    "                                                    values='steps_count',\n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu', ax=ax[0])\n",
    "sn.heatmap(path_unfinished_length_categories , cmap='BuPu', ax=ax[1])\n",
    "ax[0].set_title(\"Finished Paths\")\n",
    "ax[1].set_title(\"Unfinished Paths\")\n",
    "fig.suptitle(\"Heatmap of length of path (number of steps) for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of rating between starting subject and ending subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_finished_length_categories = paths_finished.pivot_table(index='start_category', \n",
    "                                                    columns='end_category', \n",
    "                                                    values='rating', \n",
    "                                                    aggfunc='mean')\n",
    "\n",
    "sn.heatmap(path_finished_length_categories , cmap='BuPu')\n",
    "plt.title(\"Heatmap of rating for Each Start-End Category Combination\")\n",
    "plt.xlabel(\"End Category\")\n",
    "plt.ylabel(\"Start Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the rating, the backclip number and the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "paths_finished = extract_category_path(df_finished, df_categories_filtered)\n",
    "paths_finished = backtrack(paths_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "back_per_rating = paths_finished.groupby(\"rating\").agg({\"back_nb\": \"mean\", \"size\": \"mean\"}).reset_index()\n",
    "back_per_rating['Mean Back Clicks number'] = back_per_rating[\"back_nb\"]/back_per_rating[\"size\"]\n",
    "sn.barplot(x=\"rating\", y='Mean Back Clicks number', hue=\"rating\", data=back_per_rating, palette=sn.color_palette('viridis'), ax=ax[0])\n",
    "\n",
    "df_exploded = paths_finished.explode('category')\n",
    "category_back_mean = df_exploded.groupby(['category', 'rating']).size().reset_index(name='size')\n",
    "back_mean = df_exploded.groupby('category')[\"have_back\"].mean().reset_index().sort_values(by='have_back', ascending=False)\n",
    "category_back_mean = category_back_mean.merge(back_mean, on='category').sort_values(by='have_back', ascending=False)\n",
    "category_back_mean['rating_proportion'] = category_back_mean.groupby('category')['size'].transform(lambda x: x / x.sum())\n",
    "\n",
    "order = category_back_mean[\"category\"].unique()\n",
    "base_heights = category_back_mean[['category', 'have_back']].drop_duplicates().set_index('category')['have_back']\n",
    "df_pivot = category_back_mean.pivot(index='category', columns='rating', values='rating_proportion').fillna(0)\n",
    "df_pivot = df_pivot.reindex(order)\n",
    "\n",
    "colors = sn.color_palette('viridis')\n",
    "\n",
    "bottom = pd.Series([0] * len(df_pivot), index=df_pivot.index)\n",
    "for i, rating in enumerate(df_pivot.columns):\n",
    "    ax[1].bar(df_pivot.index, \n",
    "           height=df_pivot[rating] * base_heights,  \n",
    "           bottom=bottom * base_heights,           \n",
    "           label=f'Rating {rating}', \n",
    "           color=colors[i])\n",
    "    bottom += df_pivot[rating]\n",
    "\n",
    "ax[1].set_title('Mean Number of Path with Back Clicks by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Mean Number of Path with Back Clicks')\n",
    "plt.xticks(rotation=90)\n",
    "ax[0].set_title(\"Distribution of Back Clicks per Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that irrespective of the start and end categories, many players path through countries and geography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort games into voyage or not-voyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished_voyage = game_voyage_sorting(df_finished, df_categories, True, n=3)\n",
    "df_unfinished_voyage = game_voyage_sorting(df_unfinished, df_categories, False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voyage_count = (df_finished_voyage['voyage'] == 1).sum() + (df_unfinished_voyage['voyage'] == 1).sum()\n",
    "non_voyage_count = (df_finished_voyage['voyage'] == 0).sum() + (df_unfinished_voyage['voyage'] == 0).sum()\n",
    "print('out of', len(df_finished_voyage)+len(df_unfinished_voyage), 'games : ')\n",
    "print('  - ', voyage_count, ' are voyages')\n",
    "print('  - ', non_voyage_count, ' are not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Mapping for start, voyage, and end nodes\n",
    "df_finished_voyage['start_category_label'] = df_finished_voyage['start_category'].apply(lambda x: 'First in Countries/Geography' if x in ['Countries', 'Geography'] else 'First not in Countries/Geography')\n",
    "df_finished_voyage['end_category_label'] = df_finished_voyage['end_category'].apply(lambda x: 'Target in Countries/Geography' if x in ['Countries', 'Geography'] else 'Target not in Countries/Geography')\n",
    "df_finished_voyage['voyage_label'] = df_finished_voyage['voyage'].apply(lambda x: 'Voyage' if x else 'Non-Voyage')\n",
    "\n",
    "# Count occurrences for each flow from start -> voyage -> end\n",
    "flows = df_finished_voyage.groupby(['start_category_label', 'voyage_label', 'end_category_label']).size().reset_index(name='count')\n",
    "\n",
    "# Define nodes for the Sankey diagram\n",
    "labels = ['First in Countries/Geography', 'First not in Countries/Geography',\n",
    "          'Voyage', 'Non-Voyage',\n",
    "          'Target in Countries/Geography', 'Target not in Countries/Geography']\n",
    "\n",
    "# Create mappings for source and target node indices\n",
    "label_map = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Map flows to Sankey source, target, and value arrays\n",
    "sources = []\n",
    "targets = []\n",
    "values = []\n",
    "\n",
    "for _, row in flows.iterrows():\n",
    "    # Add start -> voyage\n",
    "    sources.append(label_map[row['start_category_label']])\n",
    "    targets.append(label_map[row['voyage_label']])\n",
    "    values.append(row['count'])\n",
    "\n",
    "    # Add voyage -> end\n",
    "    sources.append(label_map[row['voyage_label']])\n",
    "    targets.append(label_map[row['end_category_label']])\n",
    "    values.append(row['count'])\n",
    "\n",
    "\n",
    "node_colors = [\n",
    "    \"rgba(0, 128, 128, 0.6)\",  \"rgba(244,109,67,0.8)\",   \n",
    "    \"rgba(0, 128, 128, 0.6)\",  \"rgba(244,109,67,0.8)\",   \n",
    "    \"rgba(0, 128, 128, 0.6)\",  \"rgba(244,109,67,0.8)\"\n",
    "    ]\n",
    "\n",
    "link_colors = [\n",
    "    \"rgba(146,197,222,0.6)\",  \"rgba(244,109,67,0.6)\",   \n",
    "    \"rgba(146,197,222,0.6)\",  \"rgba(244,109,67,0.6)\",   \n",
    "    \"rgba(146,197,222,0.6)\",  \"rgba(244,109,67,0.6)\"\n",
    "    ]\n",
    "\n",
    "# Create the Sankey plot\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(pad=15, thickness=20, line=dict(color=\"white\", width=0.1), label=labels, color=node_colors),\n",
    "    link=dict(source=sources, target=targets, value=values)\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Path classification as Voyage or not\",\n",
    "    font_size=10,\n",
    "    title_font_size=14,\n",
    "    title_x=0.5,\n",
    "    plot_bgcolor=\"white\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, leaves_list\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "linkage_matrix = linkage(similarity_matrix, method='ward')\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(linkage_matrix)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Article Index (sorted by similarity)')\n",
    "plt.tick_params(\n",
    "    axis='x',          \n",
    "    which='both',      \n",
    "    bottom=False,      \n",
    "    top=False,    \n",
    "    labelbottom=False)\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Analysis (Hierarchical Clustering)\n",
    "Find clusters of words that are more similar to each other than to words in other clusters. At the bottom of the tree, most similar pairs are formed, then pairs of pairs are compared and so on. Check out <a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html> this link </a> for more detail and <a href=https://stackoverflow.com/questions/66969893/scipy-and-the-hierarchical-clustering-input> this </a> or <a href=https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial> this link </a> to get a somewhat intuitive idea how how 2D clustering works. The clustering allows to reorder the similarity matrix in a way that regroups articles with high similarity. More analysis needs to be done to understand what the clusters essentially are and represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(df_sm, cmap='BuPu')\n",
    "cbar = fig.colorbar(cax)\n",
    "plt.title('Cosine similarity of article names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "upper_triangle_indices = np.triu_indices_from(similarity_matrix, k=1) # Flatten the upper triangle of the matrix without the diagonal for sorting\n",
    "\n",
    "# Get the sorted indices for most similar pairs (descending order)\n",
    "sorted_similar_indices = np.argsort(-similarity_matrix[upper_triangle_indices])\n",
    "top_similar_pairs = list(zip(upper_triangle_indices[0][sorted_similar_indices], \n",
    "                             upper_triangle_indices[1][sorted_similar_indices]))\n",
    "\n",
    "print(\"Top 5 most similar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_similar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {similarity_matrix[idx1, idx2]:.4f}\")\n",
    "\n",
    "sorted_dissimilar_indices = np.argsort(similarity_matrix[upper_triangle_indices])\n",
    "top_dissimilar_pairs = list(zip(upper_triangle_indices[0][sorted_dissimilar_indices], \n",
    "                                upper_triangle_indices[1][sorted_dissimilar_indices]))\n",
    "\n",
    "# Print the top 5 most dissimilar pairs\n",
    "print(\"\\nTop 5 most dissimilar pairs:\")\n",
    "for i, (idx1, idx2) in enumerate(top_dissimilar_pairs[:5]):\n",
    "    print(f\"Pair {i+1}: Articles '{df_article_names[idx1]}' and '{df_article_names[idx2]}' with similarity {similarity_matrix[idx1, idx2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_indices = leaves_list(linkage_matrix)\n",
    "reordered_matrix = similarity_matrix[ordered_indices, :][:, ordered_indices]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(reordered_matrix, cmap='BuPu')\n",
    "plt.title('Reordered Similarity Matrix')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The reordered article indices make intuitive sense, similar words are regrouped')\n",
    "print(df_article_names[ordered_indices].head(10))\n",
    "print(df_article_names[ordered_indices].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of similarity on paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unfinished = read_unfinished_paths()\n",
    "df_finished = read_finished_paths()\n",
    "\n",
    "all_paths = []\n",
    "df_finished['path'].apply(lambda x: all_paths.append(x.split(';')))\n",
    "for path in all_paths:\n",
    "    for step in range(len(path)):\n",
    "        if path[step] == '<':\n",
    "            path[step] = path[step-2]\n",
    "\n",
    "step_similarity = []\n",
    "\n",
    "for path in all_paths:\n",
    "    path_similarity = []\n",
    "    for step in range(len(path)-1):\n",
    "        current, next = sm.get_indices(df_article_names, [path[step], path[step+1]])\n",
    "        path_similarity.append(similarity_matrix[current, next])\n",
    "\n",
    "    step_similarity.append(path_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_similarity = []\n",
    "for N in range(1, 17):\n",
    "    paths_len_N = []\n",
    "    for path in step_similarity:\n",
    "        if len(path)==N:\n",
    "            paths_len_N.append(path)\n",
    "\n",
    "    paths_similarity.append(np.array(paths_len_N))\n",
    "means = [np.mean(paths_len_N, axis=0) for paths_len_N in paths_similarity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "for i in range(len(paths_similarity)):\n",
    "    plt.subplot(4, 4, 1+i)\n",
    "    plt.plot(paths_similarity[i].T, 'b.', alpha=0.5)\n",
    "    plt.plot(means[i], 'r', lw=2)\n",
    "    plt.title(f'Path length {i}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### html Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = htmlParser()\n",
    "print(f'There are {len(parser.article_URLs)} valid articles')\n",
    "\n",
    "df_html_articles = parser.article_names # The html articles in the data\n",
    "df_article_names = read_articles() # The articles used in the paths-and-graph data\n",
    "intersect = pd.merge(df_html_articles, df_article_names, how='inner', on=\"article\")\n",
    "print(f'There are {len(df_article_names)} articles in the paths-and-graph data and {len(intersect)} of those are in the html articles.')\n",
    "difference = df_html_articles[~df_html_articles.isin(df_article_names)]\n",
    "print(f'This means there are {len(difference)} articles more in the html data, such as \"{difference.iloc[0]}\", \"{difference.iloc[5]}\" or \"{difference.iloc[10]}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parser.parse_html_article(parser.article_URLs[266])\n",
    "if parsed: parser.get_overview(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_stats = parser2.get_df_html_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "sort_column = widgets.Dropdown(\n",
    "    options=df_html_stats.columns,\n",
    "    value='total_words',\n",
    "    description='Sort by:'\n",
    ")\n",
    "\n",
    "n_slider = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Number (n):'\n",
    ")\n",
    "\n",
    "# Display function to update table based on widget values\n",
    "def display_sorted(n, sort_by):\n",
    "    sorted_df = df_html_stats.sort_values(by=sort_by, ascending=False)\n",
    "    top_n = sorted_df.head(n)\n",
    "    bottom_n = sorted_df.tail(n)\n",
    "    \n",
    "    print(f\"\\nTop {n} Articles by {sort_by}:\")\n",
    "    display(top_n)\n",
    "    print(f\"\\nBottom {n} Articles by {sort_by}:\")\n",
    "    display(bottom_n)\n",
    "\n",
    "# Link widgets to display function\n",
    "widgets.interactive(display_sorted, n=n_slider, sort_by=sort_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# David Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import *\n",
    "import plotly.graph_objects as go\n",
    "from src.helpers import create_treemap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = read_categories()\n",
    "labels, parents, values, ids = create_treemap_data(df_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the treemap\n",
    "fig = go.Figure(go.Treemap(\n",
    "    labels=labels,\n",
    "    parents=parents,\n",
    "    values=values,\n",
    "    ids=ids,\n",
    "    #textinfo=\"label+value\",  # Show both label and value\n",
    "    textfont=dict(size=18),  # Increase font size; will automatically fit smaller labels\n",
    "\n",
    "))\n",
    "fig.update_layout(margin=dict(t=50, l=25, r=25, b=25), title=\"Category Distribution in Articles (Some articles have multiple categories, thus the sum of values is greater than the number of articles)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assing to articles with multiples categories the most specific category (category with less articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_filtered = filter_most_specific_category(df_categories)\n",
    "labels_filtered, parents_filtered, values_filtered, ids_filtered = create_treemap_data(df_categories_filtered)\n",
    "\n",
    "# Plotting the treemap\n",
    "fig = go.Figure(go.Treemap(\n",
    "    labels=labels_filtered,\n",
    "    parents=parents_filtered,\n",
    "    values=values_filtered,\n",
    "    ids=ids_filtered,\n",
    "    textfont=dict(size=18),  # Increase font size; will automatically fit smaller labels\n",
    "))\n",
    "\n",
    "fig.update_layout(margin=dict(t=50, l=25, r=25, b=25), title=\"Category Distribution in Articles (Only the most specific category is shown for each article)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common paths of transitions between categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_paths_f = analyze_categories_paths(df_finished, df_categories_filtered, omit_loops=False)\n",
    "common_paths_u = analyze_categories_paths(df_unfinished, df_categories_filtered, omit_loops=False)\n",
    "common_paths_f_nl = analyze_categories_paths(df_finished, df_categories_filtered, omit_loops=True)\n",
    "common_paths_u_nl = analyze_categories_paths(df_unfinished, df_categories_filtered, omit_loops=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
